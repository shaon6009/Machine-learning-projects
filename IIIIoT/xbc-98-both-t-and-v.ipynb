{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11131669,"sourceType":"datasetVersion","datasetId":6942599}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport xgboost as xgb\n\n# Load and clean data\ndata = pd.read_csv('/kaggle/input/afterlightgbm/lightGBMplustarget.csv')\ndata = data.replace([np.inf, -np.inf], np.nan).dropna()\nfor col in data.columns:\n    data[col] = pd.to_numeric(data[col], errors='coerce')\ndata = data.dropna().clip(lower=-1e10, upper=1e10).reset_index(drop=True)\n\n# Features and labels\nX = data.drop(columns=['Attack_Num']).astype(np.float32)\ny = data['Attack_Num']\n\n# Split dataset\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Convert to DMatrix\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndval = xgb.DMatrix(X_val, label=y_val)\n\n# Parameters with GPU support\nparams = {\n    'objective': 'multi:softmax',\n    'num_class': len(np.unique(y)),\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n    'eval_metric': 'mlogloss',\n    'learning_rate': 0.01,\n    'max_depth': 10,\n    'subsample': 0.8,\n    'colsample_bytree': 0.8,\n    'lambda': 1,\n    'alpha': 0.5,\n    'random_state': 42\n}\n\n# Store training history\nevals_result = {}\nevals = [(dtrain, 'train'), (dval, 'eval')]\n\n# Train model with early stopping\nmodel = xgb.train(\n    params=params,\n    dtrain=dtrain,\n    num_boost_round=3000,\n    evals=evals,\n    early_stopping_rounds=50,\n    evals_result=evals_result,\n    verbose_eval=100\n)\n\n# Predict on train and val sets\ny_train_pred = model.predict(dtrain)\ny_val_pred = model.predict(dval)\n\n# Evaluate\ntrain_acc = accuracy_score(y_train, y_train_pred)\nval_acc = accuracy_score(y_val, y_val_pred)\n\nprint(f\"\\nâœ… Final Training Accuracy: {train_acc:.4f}\")\nprint(f\"âœ… Final Validation Accuracy: {val_acc:.4f}\")\n\nprint(\"\\nðŸ“˜ Training Classification Report:\")\nprint(classification_report(y_train, y_train_pred))\n\nprint(\"\\nðŸ“— Validation Classification Report:\")\nprint(classification_report(y_val, y_val_pred))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:13:51.729441Z","iopub.execute_input":"2025-04-29T16:13:51.730161Z","iopub.status.idle":"2025-04-29T17:48:50.884109Z","shell.execute_reply.started":"2025-04-29T16:13:51.730130Z","shell.execute_reply":"2025-04-29T17:48:50.883345Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [16:15:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [16:15:04] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"predictor\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[0]\ttrain-mlogloss:2.25675\teval-mlogloss:2.25675\n[100]\ttrain-mlogloss:0.68242\teval-mlogloss:0.68245\n[200]\ttrain-mlogloss:0.30304\teval-mlogloss:0.30316\n[300]\ttrain-mlogloss:0.16634\teval-mlogloss:0.16654\n[400]\ttrain-mlogloss:0.11383\teval-mlogloss:0.11412\n[500]\ttrain-mlogloss:0.09264\teval-mlogloss:0.09303\n[600]\ttrain-mlogloss:0.08285\teval-mlogloss:0.08334\n[700]\ttrain-mlogloss:0.07807\teval-mlogloss:0.07863\n[800]\ttrain-mlogloss:0.07519\teval-mlogloss:0.07584\n[900]\ttrain-mlogloss:0.07308\teval-mlogloss:0.07382\n[1000]\ttrain-mlogloss:0.07154\teval-mlogloss:0.07236\n[1100]\ttrain-mlogloss:0.07032\teval-mlogloss:0.07122\n[1200]\ttrain-mlogloss:0.06921\teval-mlogloss:0.07020\n[1300]\ttrain-mlogloss:0.06816\teval-mlogloss:0.06924\n[1400]\ttrain-mlogloss:0.06721\teval-mlogloss:0.06839\n[1500]\ttrain-mlogloss:0.06631\teval-mlogloss:0.06759\n[1600]\ttrain-mlogloss:0.06544\teval-mlogloss:0.06683\n[1700]\ttrain-mlogloss:0.06463\teval-mlogloss:0.06614\n[1800]\ttrain-mlogloss:0.06390\teval-mlogloss:0.06553\n[1900]\ttrain-mlogloss:0.06320\teval-mlogloss:0.06495\n[2000]\ttrain-mlogloss:0.06258\teval-mlogloss:0.06446\n[2100]\ttrain-mlogloss:0.06202\teval-mlogloss:0.06402\n[2200]\ttrain-mlogloss:0.06149\teval-mlogloss:0.06361\n[2300]\ttrain-mlogloss:0.06099\teval-mlogloss:0.06323\n[2400]\ttrain-mlogloss:0.06055\teval-mlogloss:0.06290\n[2500]\ttrain-mlogloss:0.06011\teval-mlogloss:0.06259\n[2600]\ttrain-mlogloss:0.05971\teval-mlogloss:0.06230\n[2700]\ttrain-mlogloss:0.05933\teval-mlogloss:0.06203\n[2800]\ttrain-mlogloss:0.05898\teval-mlogloss:0.06179\n[2900]\ttrain-mlogloss:0.05865\teval-mlogloss:0.06157\n[2999]\ttrain-mlogloss:0.05834\teval-mlogloss:0.06137\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [17:42:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"\nâœ… Final Training Accuracy: 0.9819\nâœ… Final Validation Accuracy: 0.9806\n\nðŸ“˜ Training Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.99      1.00   4879575\n           1       1.00      1.00      1.00   3025135\n           2       0.94      0.98      0.96   1964016\n           3       0.99      0.99      0.99   1620987\n           4       0.97      0.96      0.97    922658\n           5       0.91      0.93      0.92    570087\n           6       0.97      0.88      0.93    547572\n           7       1.00      1.00      1.00     13447\n           8       0.99      0.41      0.58      6179\n           9       1.00      1.00      1.00      2740\n\n    accuracy                           0.98  13552396\n   macro avg       0.98      0.91      0.93  13552396\nweighted avg       0.98      0.98      0.98  13552396\n\n\nðŸ“— Validation Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.99      1.00   1219894\n           1       1.00      0.99      1.00    756284\n           2       0.94      0.98      0.96    491004\n           3       0.99      0.99      0.99    405247\n           4       0.97      0.96      0.96    230665\n           5       0.91      0.93      0.92    142522\n           6       0.97      0.88      0.92    136893\n           7       1.00      1.00      1.00      3362\n           8       0.94      0.38      0.54      1544\n           9       0.99      0.99      0.99       685\n\n    accuracy                           0.98   3388100\n   macro avg       0.97      0.91      0.93   3388100\nweighted avg       0.98      0.98      0.98   3388100\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom imblearn.over_sampling import SMOTE\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import to_categorical\nimport tensorflow_addons as tfa\nfrom keras_tabnet.models import TabNetClassifier\nimport xgboost as xgb\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.base import BaseEstimator, ClassifierMixin\n\ndata = pd.read_csv('/kaggle/input/afterlightgbm/lightGBMplustarget.csv')\ndata = data.replace([np.inf, -np.inf], np.nan).dropna()\nfor col in data.columns:\n    data[col] = pd.to_numeric(data[col], errors='coerce')\ndata = data.dropna().clip(lower=-1e10, upper=1e10).reset_index(drop=True)\n\nX = data.drop(columns=['Attack_Num']).astype(np.float32)\ny = data['Attack_Num']\nnum_classes = len(np.unique(y))\n\nX_trainval, X_test, y_trainval, y_test = train_test_split(\n    X, y, test_size=0.1, random_state=42, stratify=y\n)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_trainval, y_trainval, test_size=0.2, random_state=42, stratify=y_trainval\n)\n\nsm = SMOTE(random_state=42)\nX_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_smote)\nX_val_scaled = scaler.transform(X_val)\nX_test_scaled = scaler.transform(X_test)\n\ny_train_cat = to_categorical(y_train_smote, num_classes)\ny_val_cat = to_categorical(y_val, num_classes)\ny_test_cat = to_categorical(y_test, num_classes)\n\ndef build_keras_model(input_dim, num_classes):\n    model = keras.Sequential([\n        keras.layers.Input(shape=(input_dim,)),\n        keras.layers.Dense(1024, activation='swish'),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dropout(0.4),\n        keras.layers.Dense(512, activation='swish'),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dropout(0.4),\n        keras.layers.Dense(256, activation='swish'),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(num_classes, activation='softmax')\n    ])\n    model.compile(\n        optimizer=keras.optimizers.Adam(0.0005),\n        loss=tfa.losses.SigmoidFocalCrossEntropy(),\n        metrics=['accuracy']\n    )\n    return model\n\nkeras_model = build_keras_model(X_train_scaled.shape[1], num_classes)\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\nlr_schedule = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, min_lr=1e-6)\n\nkeras_model.fit(\n    X_train_scaled, y_train_cat,\n    validation_data=(X_val_scaled, y_val_cat),\n    epochs=100,\n    batch_size=512,\n    callbacks=[early_stop, lr_schedule],\n    verbose=2\n)\n\ntabnet = TabNetClassifier(verbose=0)\ntabnet.fit(\n    X_train_smote.values, y_train_smote.values,\n    eval_set=[(X_val.values, y_val.values)],\n    patience=15,\n    max_epochs=200\n)\n\nxgb_model = xgb.XGBClassifier(\n    objective='multi:softmax',\n    num_class=num_classes,\n    tree_method='gpu_hist',\n    predictor='gpu_predictor',\n    learning_rate=0.01,\n    max_depth=10,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    n_estimators=500,\n    random_state=42\n)\nxgb_model.fit(X_train_smote, y_train_smote)\n\nclass KerasClassifierWrapper(BaseEstimator, ClassifierMixin):\n    def __init__(self, model):\n        self.model = model\n    def fit(self, X, y): return self\n    def predict(self, X):\n        return np.argmax(self.model.predict(X), axis=1)\n\nensemble = VotingClassifier(estimators=[\n    ('keras', KerasClassifierWrapper(keras_model)),\n    ('tabnet', tabnet),\n    ('xgb', xgb_model)\n], voting='soft')\n\nensemble.fit(X_val_scaled, y_val) \n\nensemble_preds = ensemble.predict(X_test_scaled)\nprint(f\"\\nâœ… Ensemble Test Accuracy: {accuracy_score(y_test, ensemble_preds):.4f}\")\nprint(\"\\nðŸ“™ Ensemble Test Classification Report:\")\nprint(classification_report(y_test, ensemble_preds))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T18:39:59.122548Z","iopub.execute_input":"2025-04-29T18:39:59.122861Z","iopub.status.idle":"2025-04-29T18:40:05.860266Z","shell.execute_reply.started":"2025-04-29T18:39:59.122840Z","shell.execute_reply":"2025-04-29T18:40:05.859376Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, accuracy_score\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\ndata = pd.read_csv('/kaggle/input/afterlightgbm/lightGBMplustarget.csv')\ndata = data.replace([np.inf, -np.inf], np.nan).dropna()\nfor col in data.columns:\n    data[col] = pd.to_numeric(data[col], errors='coerce')\ndata = data.dropna().clip(lower=-1e10, upper=1e10).reset_index(drop=True)\n\nX = data.drop(columns=['Attack_Num']).astype(np.float32)\ny = data['Attack_Num']\n\nX_trainval, X_test, y_trainval, y_test = train_test_split(\n    X, y, test_size=0.1, random_state=42, stratify=y\n)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_trainval, y_trainval, test_size=0.2, random_state=42, stratify=y_trainval\n)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\nX_test_scaled = scaler.transform(X_test)\n\nnum_classes = len(np.unique(y))\ny_train_cat = keras.utils.to_categorical(y_train, num_classes)\ny_val_cat = keras.utils.to_categorical(y_val, num_classes)\ny_test_cat = keras.utils.to_categorical(y_test, num_classes)\n\ndef build_model(input_dim, num_classes):\n    return keras.Sequential([\n        layers.Input(shape=(input_dim,)),\n        layers.Dense(1024, activation='swish'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.4),\n        layers.Dense(512, activation='swish'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.4),\n        layers.Dense(256, activation='swish'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n        layers.Dense(128, activation='swish'),\n        layers.BatchNormalization(),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n\nmodel = build_model(X_train_scaled.shape[1], num_classes)\nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nearly_stop = keras.callbacks.EarlyStopping(\n    monitor='val_accuracy', patience=15, restore_best_weights=True, verbose=1\n)\nlr_schedule = keras.callbacks.ReduceLROnPlateau(\n    monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-6\n)\n\nhistory = model.fit(\n    X_train_scaled, y_train_cat,\n    validation_data=(X_val_scaled, y_val_cat),\n    epochs=100,\n    batch_size=512,\n    callbacks=[early_stop, lr_schedule],\n    verbose=2\n)\n\ny_train_pred = np.argmax(model.predict(X_train_scaled), axis=1)\ny_val_pred = np.argmax(model.predict(X_val_scaled), axis=1)\ny_test_pred = np.argmax(model.predict(X_test_scaled), axis=1)\n\nprint(f\"\\nâœ… Final Training Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\nprint(f\"âœ… Final Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\nprint(f\"âœ… Final Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n\nprint(\"\\nðŸ“˜ Training Classification Report:\")\nprint(classification_report(y_train, y_train_pred))\n\nprint(\"\\nðŸ“— Validation Classification Report:\")\nprint(classification_report(y_val, y_val_pred))\n\nprint(\"\\nðŸ“™ Test Classification Report:\")\nprint(classification_report(y_test, y_test_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T18:14:12.524005Z","iopub.execute_input":"2025-04-29T18:14:12.524521Z","iopub.status.idle":"2025-04-29T18:33:24.110595Z","shell.execute_reply.started":"2025-04-29T18:14:12.524491Z","shell.execute_reply":"2025-04-29T18:33:24.109437Z"}},"outputs":[{"name":"stderr","text":"2025-04-29 18:14:15.962380: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745950456.162004     372 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745950456.216793     372 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nI0000 00:00:1745950546.534486     372 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1745950546.535144     372 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1745950557.254031     410 service.cc:148] XLA service 0x783cd4019a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1745950557.254650     410 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1745950557.254676     410 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1745950557.719196     410 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1745950561.204311     410 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"23823/23823 - 78s - 3ms/step - accuracy: 0.9372 - loss: 0.1812 - val_accuracy: 0.9584 - val_loss: 0.1233 - learning_rate: 5.0000e-04\nEpoch 2/100\n23823/23823 - 63s - 3ms/step - accuracy: 0.9557 - loss: 0.1306 - val_accuracy: 0.9300 - val_loss: 0.1730 - learning_rate: 5.0000e-04\nEpoch 3/100\n23823/23823 - 64s - 3ms/step - accuracy: 0.9573 - loss: 0.1258 - val_accuracy: 0.9623 - val_loss: 0.1127 - learning_rate: 5.0000e-04\nEpoch 4/100\n23823/23823 - 64s - 3ms/step - accuracy: 0.9593 - loss: 0.1201 - val_accuracy: 0.9628 - val_loss: 0.1112 - learning_rate: 5.0000e-04\nEpoch 5/100\n23823/23823 - 64s - 3ms/step - accuracy: 0.9602 - loss: 0.1172 - val_accuracy: 0.9643 - val_loss: 0.1060 - learning_rate: 5.0000e-04\nEpoch 6/100\n23823/23823 - 63s - 3ms/step - accuracy: 0.9609 - loss: 0.1148 - val_accuracy: 0.9648 - val_loss: 0.1042 - learning_rate: 5.0000e-04\nEpoch 7/100\n23823/23823 - 63s - 3ms/step - accuracy: 0.9616 - loss: 0.1128 - val_accuracy: 0.9650 - val_loss: 0.1031 - learning_rate: 5.0000e-04\nEpoch 8/100\n23823/23823 - 63s - 3ms/step - accuracy: 0.9621 - loss: 0.1112 - val_accuracy: 0.9659 - val_loss: 0.1013 - learning_rate: 5.0000e-04\nEpoch 9/100\n23823/23823 - 63s - 3ms/step - accuracy: 0.9626 - loss: 0.1101 - val_accuracy: 0.9659 - val_loss: 0.1006 - learning_rate: 5.0000e-04\nEpoch 10/100\n23823/23823 - 63s - 3ms/step - accuracy: 0.9629 - loss: 0.1090 - val_accuracy: 0.9655 - val_loss: 0.1008 - learning_rate: 5.0000e-04\nEpoch 11/100\n23823/23823 - 63s - 3ms/step - accuracy: 0.9632 - loss: 0.1080 - val_accuracy: 0.9657 - val_loss: 0.1009 - learning_rate: 5.0000e-04\nEpoch 12/100\n23823/23823 - 63s - 3ms/step - accuracy: 0.9634 - loss: 0.1073 - val_accuracy: 0.9663 - val_loss: 0.0986 - learning_rate: 5.0000e-04\nEpoch 13/100\n23823/23823 - 63s - 3ms/step - accuracy: 0.9637 - loss: 0.1066 - val_accuracy: 0.9666 - val_loss: 0.1002 - learning_rate: 5.0000e-04\nEpoch 14/100\n23823/23823 - 63s - 3ms/step - accuracy: 0.9639 - loss: 0.1060 - val_accuracy: 0.9667 - val_loss: 0.0978 - learning_rate: 5.0000e-04\nEpoch 15/100\n23823/23823 - 63s - 3ms/step - accuracy: 0.9640 - loss: 0.1055 - val_accuracy: 0.9667 - val_loss: 0.0970 - learning_rate: 5.0000e-04\nEpoch 16/100\n23823/23823 - 63s - 3ms/step - accuracy: 0.9642 - loss: 0.1049 - val_accuracy: 0.9666 - val_loss: 0.0968 - learning_rate: 5.0000e-04\nEpoch 17/100\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_372/2472129025.py\", line 76, in <cell line: 0>\n    history = model.fit(\n              ^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n    logs = self.train_function(iterator)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n    result = self._call(*args, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n    results = tracing_compilation.call_function(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 132, in call_function\n    function = trace_function(\n               ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 178, in trace_function\n    concrete_function = _maybe_define_function(\n                        ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 212, in _maybe_define_function\n    args, kwargs = bound_args.args, bound_args.kwargs\n                   ^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/inspect.py\", line 2841, in args\n    args.append(arg)\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n    stb = value._render_traceback_()\n          ^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n    traceback_info = getframeinfo(tb, context)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/inspect.py\", line 1684, in getframeinfo\n    filename = getsourcefile(frame) or getfile(frame)\n               ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n    module = getmodule(object, filename)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/inspect.py\", line 994, in getmodule\n    f = getabsfile(module)\n        ^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/inspect.py\", line 963, in getabsfile\n    _filename = getsourcefile(object) or getfile(object)\n                ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/inspect.py\", line 945, in getsourcefile\n    if os.path.exists(filename):\n       ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen genericpath>\", line 19, in exists\nKeyboardInterrupt\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_372/2472129025.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# 9. Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m   function = trace_function(\n\u001b[0m\u001b[1;32m    133\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    211\u001b[0m   )\n\u001b[0;32m--> 212\u001b[0;31m   \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36margs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2840\u001b[0m                     \u001b[0;31m# plain argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2841\u001b[0;31m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"],"ename":"TypeError","evalue":"object of type 'NoneType' has no len()","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"%%capture\npip install --upgrade numpy pandas imbalanced-learn xgboost keras-tabnet tensorflow-addons","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T18:35:51.451626Z","iopub.execute_input":"2025-04-29T18:35:51.452161Z","iopub.status.idle":"2025-04-29T18:35:54.038551Z","shell.execute_reply.started":"2025-04-29T18:35:51.452127Z","shell.execute_reply":"2025-04-29T18:35:54.037581Z"}},"outputs":[],"execution_count":8}]}