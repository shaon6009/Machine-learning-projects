{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":723448,"sourceType":"datasetVersion","datasetId":371805}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_regression\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport plotly.express as px\n%matplotlib inline\n\nsns.set_style('darkgrid')\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (10, 6)\nmatplotlib.rcParams['figure.facecolor'] = '#00000000'\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix, classification_report)\nfrom sklearn.exceptions import NotFittedError\n\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier,\n                              GradientBoostingClassifier, BaggingClassifier, HistGradientBoostingClassifier)\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.neural_network import MLPClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-20T21:51:06.342045Z","iopub.execute_input":"2024-09-20T21:51:06.343164Z","iopub.status.idle":"2024-09-20T21:51:06.356983Z","shell.execute_reply.started":"2024-09-20T21:51:06.343115Z","shell.execute_reply":"2024-09-20T21:51:06.355755Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data= pd.read_csv('/kaggle/input/framingham/framingham.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.359377Z","iopub.execute_input":"2024-09-20T21:51:06.360446Z","iopub.status.idle":"2024-09-20T21:51:06.412784Z","shell.execute_reply.started":"2024-09-20T21:51:06.360395Z","shell.execute_reply":"2024-09-20T21:51:06.411878Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"         Sex  age  education currentSmoker  cigsPerDay  BPMeds  \\\n0       male   39        4.0            No         0.0     0.0   \n1     female   46        2.0            No         0.0     0.0   \n2       male   48        1.0           Yes        20.0     0.0   \n3     female   61        3.0           Yes        30.0     0.0   \n4     female   46        3.0           Yes        23.0     0.0   \n...      ...  ...        ...           ...         ...     ...   \n4235  female   48        2.0           Yes        20.0     NaN   \n4236  female   44        1.0           Yes        15.0     0.0   \n4237  female   52        2.0            No         0.0     0.0   \n4238    male   40        3.0            No         0.0     0.0   \n4239  female   39        3.0           Yes        30.0     0.0   \n\n      prevalentStroke  prevalentHyp diabetes  totChol  sysBP  diaBP    BMI  \\\n0                   0             0       No    195.0  106.0   70.0  26.97   \n1                   0             0       No    250.0  121.0   81.0  28.73   \n2                   0             0       No    245.0  127.5   80.0  25.34   \n3                   0             1       No    225.0  150.0   95.0  28.58   \n4                   0             0       No    285.0  130.0   84.0  23.10   \n...               ...           ...      ...      ...    ...    ...    ...   \n4235                0             0       No    248.0  131.0   72.0  22.00   \n4236                0             0       No    210.0  126.5   87.0  19.16   \n4237                0             0       No    269.0  133.5   83.0  21.47   \n4238                0             1       No    185.0  141.0   98.0  25.60   \n4239                0             0       No    196.0  133.0   86.0  20.91   \n\n      heartRate  glucose  TenYearCHD  \n0          80.0     77.0           0  \n1          95.0     76.0           0  \n2          75.0     70.0           0  \n3          65.0    103.0           1  \n4          85.0     85.0           0  \n...         ...      ...         ...  \n4235       84.0     86.0           0  \n4236       86.0      NaN           0  \n4237       80.0    107.0           0  \n4238       67.0     72.0           0  \n4239       85.0     80.0           0  \n\n[4240 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>age</th>\n      <th>education</th>\n      <th>currentSmoker</th>\n      <th>cigsPerDay</th>\n      <th>BPMeds</th>\n      <th>prevalentStroke</th>\n      <th>prevalentHyp</th>\n      <th>diabetes</th>\n      <th>totChol</th>\n      <th>sysBP</th>\n      <th>diaBP</th>\n      <th>BMI</th>\n      <th>heartRate</th>\n      <th>glucose</th>\n      <th>TenYearCHD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>male</td>\n      <td>39</td>\n      <td>4.0</td>\n      <td>No</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>195.0</td>\n      <td>106.0</td>\n      <td>70.0</td>\n      <td>26.97</td>\n      <td>80.0</td>\n      <td>77.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>46</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>250.0</td>\n      <td>121.0</td>\n      <td>81.0</td>\n      <td>28.73</td>\n      <td>95.0</td>\n      <td>76.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>male</td>\n      <td>48</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>245.0</td>\n      <td>127.5</td>\n      <td>80.0</td>\n      <td>25.34</td>\n      <td>75.0</td>\n      <td>70.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>female</td>\n      <td>61</td>\n      <td>3.0</td>\n      <td>Yes</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>No</td>\n      <td>225.0</td>\n      <td>150.0</td>\n      <td>95.0</td>\n      <td>28.58</td>\n      <td>65.0</td>\n      <td>103.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>female</td>\n      <td>46</td>\n      <td>3.0</td>\n      <td>Yes</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>285.0</td>\n      <td>130.0</td>\n      <td>84.0</td>\n      <td>23.10</td>\n      <td>85.0</td>\n      <td>85.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4235</th>\n      <td>female</td>\n      <td>48</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>248.0</td>\n      <td>131.0</td>\n      <td>72.0</td>\n      <td>22.00</td>\n      <td>84.0</td>\n      <td>86.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4236</th>\n      <td>female</td>\n      <td>44</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>210.0</td>\n      <td>126.5</td>\n      <td>87.0</td>\n      <td>19.16</td>\n      <td>86.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4237</th>\n      <td>female</td>\n      <td>52</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>269.0</td>\n      <td>133.5</td>\n      <td>83.0</td>\n      <td>21.47</td>\n      <td>80.0</td>\n      <td>107.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4238</th>\n      <td>male</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>No</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>No</td>\n      <td>185.0</td>\n      <td>141.0</td>\n      <td>98.0</td>\n      <td>25.60</td>\n      <td>67.0</td>\n      <td>72.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4239</th>\n      <td>female</td>\n      <td>39</td>\n      <td>3.0</td>\n      <td>Yes</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>196.0</td>\n      <td>133.0</td>\n      <td>86.0</td>\n      <td>20.91</td>\n      <td>85.0</td>\n      <td>80.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4240 rows × 16 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.414315Z","iopub.execute_input":"2024-09-20T21:51:06.414746Z","iopub.status.idle":"2024-09-20T21:51:06.431778Z","shell.execute_reply.started":"2024-09-20T21:51:06.414695Z","shell.execute_reply":"2024-09-20T21:51:06.430748Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4240 entries, 0 to 4239\nData columns (total 16 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Sex              4240 non-null   object \n 1   age              4240 non-null   int64  \n 2   education        4135 non-null   float64\n 3   currentSmoker    4240 non-null   object \n 4   cigsPerDay       4211 non-null   float64\n 5   BPMeds           4187 non-null   float64\n 6   prevalentStroke  4240 non-null   int64  \n 7   prevalentHyp     4240 non-null   int64  \n 8   diabetes         4240 non-null   object \n 9   totChol          4190 non-null   float64\n 10  sysBP            4240 non-null   float64\n 11  diaBP            4240 non-null   float64\n 12  BMI              4221 non-null   float64\n 13  heartRate        4239 non-null   float64\n 14  glucose          3852 non-null   float64\n 15  TenYearCHD       4240 non-null   int64  \ndtypes: float64(9), int64(4), object(3)\nmemory usage: 530.1+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.433844Z","iopub.execute_input":"2024-09-20T21:51:06.434178Z","iopub.status.idle":"2024-09-20T21:51:06.444193Z","shell.execute_reply.started":"2024-09-20T21:51:06.434142Z","shell.execute_reply":"2024-09-20T21:51:06.443297Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Sex                  0\nage                  0\neducation          105\ncurrentSmoker        0\ncigsPerDay          29\nBPMeds              53\nprevalentStroke      0\nprevalentHyp         0\ndiabetes             0\ntotChol             50\nsysBP                0\ndiaBP                0\nBMI                 19\nheartRate            1\nglucose            388\nTenYearCHD           0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"round(data.describe().T,2)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.445634Z","iopub.execute_input":"2024-09-20T21:51:06.446112Z","iopub.status.idle":"2024-09-20T21:51:06.499194Z","shell.execute_reply.started":"2024-09-20T21:51:06.446061Z","shell.execute_reply":"2024-09-20T21:51:06.498190Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                  count    mean    std     min     25%    50%     75%    max\nage              4240.0   49.58   8.57   32.00   42.00   49.0   56.00   70.0\neducation        4135.0    1.98   1.02    1.00    1.00    2.0    3.00    4.0\ncigsPerDay       4211.0    9.01  11.92    0.00    0.00    0.0   20.00   70.0\nBPMeds           4187.0    0.03   0.17    0.00    0.00    0.0    0.00    1.0\nprevalentStroke  4240.0    0.01   0.08    0.00    0.00    0.0    0.00    1.0\nprevalentHyp     4240.0    0.31   0.46    0.00    0.00    0.0    1.00    1.0\ntotChol          4190.0  236.70  44.59  107.00  206.00  234.0  263.00  696.0\nsysBP            4240.0  132.35  22.03   83.50  117.00  128.0  144.00  295.0\ndiaBP            4240.0   82.90  11.91   48.00   75.00   82.0   90.00  142.5\nBMI              4221.0   25.80   4.08   15.54   23.07   25.4   28.04   56.8\nheartRate        4239.0   75.88  12.03   44.00   68.00   75.0   83.00  143.0\nglucose          3852.0   81.96  23.95   40.00   71.00   78.0   87.00  394.0\nTenYearCHD       4240.0    0.15   0.36    0.00    0.00    0.0    0.00    1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>4240.0</td>\n      <td>49.58</td>\n      <td>8.57</td>\n      <td>32.00</td>\n      <td>42.00</td>\n      <td>49.0</td>\n      <td>56.00</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>education</th>\n      <td>4135.0</td>\n      <td>1.98</td>\n      <td>1.02</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.0</td>\n      <td>3.00</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>cigsPerDay</th>\n      <td>4211.0</td>\n      <td>9.01</td>\n      <td>11.92</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>20.00</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>BPMeds</th>\n      <td>4187.0</td>\n      <td>0.03</td>\n      <td>0.17</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>prevalentStroke</th>\n      <td>4240.0</td>\n      <td>0.01</td>\n      <td>0.08</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>prevalentHyp</th>\n      <td>4240.0</td>\n      <td>0.31</td>\n      <td>0.46</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>totChol</th>\n      <td>4190.0</td>\n      <td>236.70</td>\n      <td>44.59</td>\n      <td>107.00</td>\n      <td>206.00</td>\n      <td>234.0</td>\n      <td>263.00</td>\n      <td>696.0</td>\n    </tr>\n    <tr>\n      <th>sysBP</th>\n      <td>4240.0</td>\n      <td>132.35</td>\n      <td>22.03</td>\n      <td>83.50</td>\n      <td>117.00</td>\n      <td>128.0</td>\n      <td>144.00</td>\n      <td>295.0</td>\n    </tr>\n    <tr>\n      <th>diaBP</th>\n      <td>4240.0</td>\n      <td>82.90</td>\n      <td>11.91</td>\n      <td>48.00</td>\n      <td>75.00</td>\n      <td>82.0</td>\n      <td>90.00</td>\n      <td>142.5</td>\n    </tr>\n    <tr>\n      <th>BMI</th>\n      <td>4221.0</td>\n      <td>25.80</td>\n      <td>4.08</td>\n      <td>15.54</td>\n      <td>23.07</td>\n      <td>25.4</td>\n      <td>28.04</td>\n      <td>56.8</td>\n    </tr>\n    <tr>\n      <th>heartRate</th>\n      <td>4239.0</td>\n      <td>75.88</td>\n      <td>12.03</td>\n      <td>44.00</td>\n      <td>68.00</td>\n      <td>75.0</td>\n      <td>83.00</td>\n      <td>143.0</td>\n    </tr>\n    <tr>\n      <th>glucose</th>\n      <td>3852.0</td>\n      <td>81.96</td>\n      <td>23.95</td>\n      <td>40.00</td>\n      <td>71.00</td>\n      <td>78.0</td>\n      <td>87.00</td>\n      <td>394.0</td>\n    </tr>\n    <tr>\n      <th>TenYearCHD</th>\n      <td>4240.0</td>\n      <td>0.15</td>\n      <td>0.36</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# data.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.500434Z","iopub.execute_input":"2024-09-20T21:51:06.500728Z","iopub.status.idle":"2024-09-20T21:51:06.505159Z","shell.execute_reply.started":"2024-09-20T21:51:06.500695Z","shell.execute_reply":"2024-09-20T21:51:06.504189Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# from ydata_profiling import ProfileReport\n# profile=ProfileReport(data,explorative=True,dark_mode=True)\n# profile","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.506377Z","iopub.execute_input":"2024-09-20T21:51:06.507138Z","iopub.status.idle":"2024-09-20T21:51:06.515810Z","shell.execute_reply.started":"2024-09-20T21:51:06.507093Z","shell.execute_reply":"2024-09-20T21:51:06.514647Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# data.columns","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.517029Z","iopub.execute_input":"2024-09-20T21:51:06.517373Z","iopub.status.idle":"2024-09-20T21:51:06.526184Z","shell.execute_reply.started":"2024-09-20T21:51:06.517323Z","shell.execute_reply":"2024-09-20T21:51:06.524741Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"unique_values= {}\nfor i in data.columns:\n    unique_values[i]= data[i].nunique()\n    \npd.DataFrame(unique_values,index= ['unique_value']).T","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.527335Z","iopub.execute_input":"2024-09-20T21:51:06.527712Z","iopub.status.idle":"2024-09-20T21:51:06.553148Z","shell.execute_reply.started":"2024-09-20T21:51:06.527665Z","shell.execute_reply":"2024-09-20T21:51:06.551325Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                 unique_value\nSex                         2\nage                        39\neducation                   4\ncurrentSmoker               2\ncigsPerDay                 33\nBPMeds                      2\nprevalentStroke             2\nprevalentHyp                2\ndiabetes                    2\ntotChol                   248\nsysBP                     234\ndiaBP                     146\nBMI                      1364\nheartRate                  73\nglucose                   143\nTenYearCHD                  2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Sex</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>education</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>currentSmoker</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>cigsPerDay</th>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>BPMeds</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>prevalentStroke</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>prevalentHyp</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>diabetes</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>totChol</th>\n      <td>248</td>\n    </tr>\n    <tr>\n      <th>sysBP</th>\n      <td>234</td>\n    </tr>\n    <tr>\n      <th>diaBP</th>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>BMI</th>\n      <td>1364</td>\n    </tr>\n    <tr>\n      <th>heartRate</th>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>glucose</th>\n      <td>143</td>\n    </tr>\n    <tr>\n      <th>TenYearCHD</th>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(data['Sex'].unique())","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.557757Z","iopub.execute_input":"2024-09-20T21:51:06.558897Z","iopub.status.idle":"2024-09-20T21:51:06.565531Z","shell.execute_reply.started":"2024-09-20T21:51:06.558774Z","shell.execute_reply":"2024-09-20T21:51:06.564473Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"['male' 'female']\n","output_type":"stream"}]},{"cell_type":"code","source":"data['Sex'] = data['Sex'].map({'male': 1, 'female': 0})\ndata","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.566753Z","iopub.execute_input":"2024-09-20T21:51:06.567749Z","iopub.status.idle":"2024-09-20T21:51:06.605457Z","shell.execute_reply.started":"2024-09-20T21:51:06.567685Z","shell.execute_reply":"2024-09-20T21:51:06.604345Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"      Sex  age  education currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n0       1   39        4.0            No         0.0     0.0                0   \n1       0   46        2.0            No         0.0     0.0                0   \n2       1   48        1.0           Yes        20.0     0.0                0   \n3       0   61        3.0           Yes        30.0     0.0                0   \n4       0   46        3.0           Yes        23.0     0.0                0   \n...   ...  ...        ...           ...         ...     ...              ...   \n4235    0   48        2.0           Yes        20.0     NaN                0   \n4236    0   44        1.0           Yes        15.0     0.0                0   \n4237    0   52        2.0            No         0.0     0.0                0   \n4238    1   40        3.0            No         0.0     0.0                0   \n4239    0   39        3.0           Yes        30.0     0.0                0   \n\n      prevalentHyp diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n0                0       No    195.0  106.0   70.0  26.97       80.0     77.0   \n1                0       No    250.0  121.0   81.0  28.73       95.0     76.0   \n2                0       No    245.0  127.5   80.0  25.34       75.0     70.0   \n3                1       No    225.0  150.0   95.0  28.58       65.0    103.0   \n4                0       No    285.0  130.0   84.0  23.10       85.0     85.0   \n...            ...      ...      ...    ...    ...    ...        ...      ...   \n4235             0       No    248.0  131.0   72.0  22.00       84.0     86.0   \n4236             0       No    210.0  126.5   87.0  19.16       86.0      NaN   \n4237             0       No    269.0  133.5   83.0  21.47       80.0    107.0   \n4238             1       No    185.0  141.0   98.0  25.60       67.0     72.0   \n4239             0       No    196.0  133.0   86.0  20.91       85.0     80.0   \n\n      TenYearCHD  \n0              0  \n1              0  \n2              0  \n3              1  \n4              0  \n...          ...  \n4235           0  \n4236           0  \n4237           0  \n4238           0  \n4239           0  \n\n[4240 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>age</th>\n      <th>education</th>\n      <th>currentSmoker</th>\n      <th>cigsPerDay</th>\n      <th>BPMeds</th>\n      <th>prevalentStroke</th>\n      <th>prevalentHyp</th>\n      <th>diabetes</th>\n      <th>totChol</th>\n      <th>sysBP</th>\n      <th>diaBP</th>\n      <th>BMI</th>\n      <th>heartRate</th>\n      <th>glucose</th>\n      <th>TenYearCHD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>39</td>\n      <td>4.0</td>\n      <td>No</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>195.0</td>\n      <td>106.0</td>\n      <td>70.0</td>\n      <td>26.97</td>\n      <td>80.0</td>\n      <td>77.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>46</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>250.0</td>\n      <td>121.0</td>\n      <td>81.0</td>\n      <td>28.73</td>\n      <td>95.0</td>\n      <td>76.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>48</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>245.0</td>\n      <td>127.5</td>\n      <td>80.0</td>\n      <td>25.34</td>\n      <td>75.0</td>\n      <td>70.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>61</td>\n      <td>3.0</td>\n      <td>Yes</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>No</td>\n      <td>225.0</td>\n      <td>150.0</td>\n      <td>95.0</td>\n      <td>28.58</td>\n      <td>65.0</td>\n      <td>103.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>46</td>\n      <td>3.0</td>\n      <td>Yes</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>285.0</td>\n      <td>130.0</td>\n      <td>84.0</td>\n      <td>23.10</td>\n      <td>85.0</td>\n      <td>85.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4235</th>\n      <td>0</td>\n      <td>48</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>248.0</td>\n      <td>131.0</td>\n      <td>72.0</td>\n      <td>22.00</td>\n      <td>84.0</td>\n      <td>86.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4236</th>\n      <td>0</td>\n      <td>44</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>210.0</td>\n      <td>126.5</td>\n      <td>87.0</td>\n      <td>19.16</td>\n      <td>86.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4237</th>\n      <td>0</td>\n      <td>52</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>269.0</td>\n      <td>133.5</td>\n      <td>83.0</td>\n      <td>21.47</td>\n      <td>80.0</td>\n      <td>107.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4238</th>\n      <td>1</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>No</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>No</td>\n      <td>185.0</td>\n      <td>141.0</td>\n      <td>98.0</td>\n      <td>25.60</td>\n      <td>67.0</td>\n      <td>72.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4239</th>\n      <td>0</td>\n      <td>39</td>\n      <td>3.0</td>\n      <td>Yes</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>196.0</td>\n      <td>133.0</td>\n      <td>86.0</td>\n      <td>20.91</td>\n      <td>85.0</td>\n      <td>80.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4240 rows × 16 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['currentSmoker']= data['currentSmoker'].map({'Yes':1, 'No':0})\ndata['diabetes']= data['diabetes'].map({'Yes':1, 'No':0})","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.607237Z","iopub.execute_input":"2024-09-20T21:51:06.607680Z","iopub.status.idle":"2024-09-20T21:51:06.618170Z","shell.execute_reply.started":"2024-09-20T21:51:06.607635Z","shell.execute_reply":"2024-09-20T21:51:06.616471Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.621410Z","iopub.execute_input":"2024-09-20T21:51:06.622318Z","iopub.status.idle":"2024-09-20T21:51:06.656681Z","shell.execute_reply.started":"2024-09-20T21:51:06.622252Z","shell.execute_reply":"2024-09-20T21:51:06.655417Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"      Sex  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n0       1   39        4.0              0         0.0     0.0                0   \n1       0   46        2.0              0         0.0     0.0                0   \n2       1   48        1.0              1        20.0     0.0                0   \n3       0   61        3.0              1        30.0     0.0                0   \n4       0   46        3.0              1        23.0     0.0                0   \n...   ...  ...        ...            ...         ...     ...              ...   \n4235    0   48        2.0              1        20.0     NaN                0   \n4236    0   44        1.0              1        15.0     0.0                0   \n4237    0   52        2.0              0         0.0     0.0                0   \n4238    1   40        3.0              0         0.0     0.0                0   \n4239    0   39        3.0              1        30.0     0.0                0   \n\n      prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  \\\n0                0         0    195.0  106.0   70.0  26.97       80.0   \n1                0         0    250.0  121.0   81.0  28.73       95.0   \n2                0         0    245.0  127.5   80.0  25.34       75.0   \n3                1         0    225.0  150.0   95.0  28.58       65.0   \n4                0         0    285.0  130.0   84.0  23.10       85.0   \n...            ...       ...      ...    ...    ...    ...        ...   \n4235             0         0    248.0  131.0   72.0  22.00       84.0   \n4236             0         0    210.0  126.5   87.0  19.16       86.0   \n4237             0         0    269.0  133.5   83.0  21.47       80.0   \n4238             1         0    185.0  141.0   98.0  25.60       67.0   \n4239             0         0    196.0  133.0   86.0  20.91       85.0   \n\n      glucose  TenYearCHD  \n0        77.0           0  \n1        76.0           0  \n2        70.0           0  \n3       103.0           1  \n4        85.0           0  \n...       ...         ...  \n4235     86.0           0  \n4236      NaN           0  \n4237    107.0           0  \n4238     72.0           0  \n4239     80.0           0  \n\n[4240 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>age</th>\n      <th>education</th>\n      <th>currentSmoker</th>\n      <th>cigsPerDay</th>\n      <th>BPMeds</th>\n      <th>prevalentStroke</th>\n      <th>prevalentHyp</th>\n      <th>diabetes</th>\n      <th>totChol</th>\n      <th>sysBP</th>\n      <th>diaBP</th>\n      <th>BMI</th>\n      <th>heartRate</th>\n      <th>glucose</th>\n      <th>TenYearCHD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>39</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>195.0</td>\n      <td>106.0</td>\n      <td>70.0</td>\n      <td>26.97</td>\n      <td>80.0</td>\n      <td>77.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>46</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>250.0</td>\n      <td>121.0</td>\n      <td>81.0</td>\n      <td>28.73</td>\n      <td>95.0</td>\n      <td>76.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>48</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>245.0</td>\n      <td>127.5</td>\n      <td>80.0</td>\n      <td>25.34</td>\n      <td>75.0</td>\n      <td>70.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>61</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>225.0</td>\n      <td>150.0</td>\n      <td>95.0</td>\n      <td>28.58</td>\n      <td>65.0</td>\n      <td>103.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>46</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>285.0</td>\n      <td>130.0</td>\n      <td>84.0</td>\n      <td>23.10</td>\n      <td>85.0</td>\n      <td>85.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4235</th>\n      <td>0</td>\n      <td>48</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>248.0</td>\n      <td>131.0</td>\n      <td>72.0</td>\n      <td>22.00</td>\n      <td>84.0</td>\n      <td>86.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4236</th>\n      <td>0</td>\n      <td>44</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>210.0</td>\n      <td>126.5</td>\n      <td>87.0</td>\n      <td>19.16</td>\n      <td>86.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4237</th>\n      <td>0</td>\n      <td>52</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>269.0</td>\n      <td>133.5</td>\n      <td>83.0</td>\n      <td>21.47</td>\n      <td>80.0</td>\n      <td>107.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4238</th>\n      <td>1</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>185.0</td>\n      <td>141.0</td>\n      <td>98.0</td>\n      <td>25.60</td>\n      <td>67.0</td>\n      <td>72.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4239</th>\n      <td>0</td>\n      <td>39</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>196.0</td>\n      <td>133.0</td>\n      <td>86.0</td>\n      <td>20.91</td>\n      <td>85.0</td>\n      <td>80.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4240 rows × 16 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# from sklearn import preprocessing\n# from collections import defaultdict\n# d = defaultdict(preprocessing.LabelEncoder)\n# data['Sex'] = d['Sex'].fit_transform(data['Sex'])\n# data","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.658005Z","iopub.execute_input":"2024-09-20T21:51:06.658399Z","iopub.status.idle":"2024-09-20T21:51:06.666193Z","shell.execute_reply.started":"2024-09-20T21:51:06.658359Z","shell.execute_reply":"2024-09-20T21:51:06.664519Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"data.corr()['TenYearCHD'].sort_values(ascending= False)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.668016Z","iopub.execute_input":"2024-09-20T21:51:06.669046Z","iopub.status.idle":"2024-09-20T21:51:06.689526Z","shell.execute_reply.started":"2024-09-20T21:51:06.668987Z","shell.execute_reply":"2024-09-20T21:51:06.688332Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"TenYearCHD         1.000000\nage                0.225408\nsysBP              0.216374\nprevalentHyp       0.177458\ndiaBP              0.145112\nglucose            0.125590\ndiabetes           0.097344\nSex                0.088374\nBPMeds             0.087519\ntotChol            0.082369\nBMI                0.075300\nprevalentStroke    0.061823\ncigsPerDay         0.057755\nheartRate          0.022907\ncurrentSmoker      0.019448\neducation         -0.054248\nName: TenYearCHD, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"# all undersampling at once","metadata":{}},{"cell_type":"code","source":"data.fillna(data.std(), inplace=True)\nprint(data.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.692175Z","iopub.execute_input":"2024-09-20T21:51:06.692928Z","iopub.status.idle":"2024-09-20T21:51:06.713733Z","shell.execute_reply.started":"2024-09-20T21:51:06.692876Z","shell.execute_reply":"2024-09-20T21:51:06.711528Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Sex                0\nage                0\neducation          0\ncurrentSmoker      0\ncigsPerDay         0\nBPMeds             0\nprevalentStroke    0\nprevalentHyp       0\ndiabetes           0\ntotChol            0\nsysBP              0\ndiaBP              0\nBMI                0\nheartRate          0\nglucose            0\nTenYearCHD         0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# data.drop(columns=['education'],inplace=True)\n# data\ntarget= data['TenYearCHD']\ncolumns_to_drop = ['education','TenYearCHD']\nfeatures = data.drop(columns_to_drop, axis=1)\nfeatures","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:55.988810Z","iopub.execute_input":"2024-09-20T21:51:55.989819Z","iopub.status.idle":"2024-09-20T21:51:56.021532Z","shell.execute_reply.started":"2024-09-20T21:51:55.989771Z","shell.execute_reply":"2024-09-20T21:51:56.020074Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"      Sex  age  currentSmoker  cigsPerDay    BPMeds  prevalentStroke  \\\n0       1   39              0         0.0  0.000000                0   \n1       0   46              0         0.0  0.000000                0   \n2       1   48              1        20.0  0.000000                0   \n3       0   61              1        30.0  0.000000                0   \n4       0   46              1        23.0  0.000000                0   \n...   ...  ...            ...         ...       ...              ...   \n4235    0   48              1        20.0  0.169544                0   \n4236    0   44              1        15.0  0.000000                0   \n4237    0   52              0         0.0  0.000000                0   \n4238    1   40              0         0.0  0.000000                0   \n4239    0   39              1        30.0  0.000000                0   \n\n      prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  \\\n0                0         0    195.0  106.0   70.0  26.97       80.0   \n1                0         0    250.0  121.0   81.0  28.73       95.0   \n2                0         0    245.0  127.5   80.0  25.34       75.0   \n3                1         0    225.0  150.0   95.0  28.58       65.0   \n4                0         0    285.0  130.0   84.0  23.10       85.0   \n...            ...       ...      ...    ...    ...    ...        ...   \n4235             0         0    248.0  131.0   72.0  22.00       84.0   \n4236             0         0    210.0  126.5   87.0  19.16       86.0   \n4237             0         0    269.0  133.5   83.0  21.47       80.0   \n4238             1         0    185.0  141.0   98.0  25.60       67.0   \n4239             0         0    196.0  133.0   86.0  20.91       85.0   \n\n         glucose  \n0      77.000000  \n1      76.000000  \n2      70.000000  \n3     103.000000  \n4      85.000000  \n...          ...  \n4235   86.000000  \n4236   23.954335  \n4237  107.000000  \n4238   72.000000  \n4239   80.000000  \n\n[4240 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>age</th>\n      <th>currentSmoker</th>\n      <th>cigsPerDay</th>\n      <th>BPMeds</th>\n      <th>prevalentStroke</th>\n      <th>prevalentHyp</th>\n      <th>diabetes</th>\n      <th>totChol</th>\n      <th>sysBP</th>\n      <th>diaBP</th>\n      <th>BMI</th>\n      <th>heartRate</th>\n      <th>glucose</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>39</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>195.0</td>\n      <td>106.0</td>\n      <td>70.0</td>\n      <td>26.97</td>\n      <td>80.0</td>\n      <td>77.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>46</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>250.0</td>\n      <td>121.0</td>\n      <td>81.0</td>\n      <td>28.73</td>\n      <td>95.0</td>\n      <td>76.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>48</td>\n      <td>1</td>\n      <td>20.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>245.0</td>\n      <td>127.5</td>\n      <td>80.0</td>\n      <td>25.34</td>\n      <td>75.0</td>\n      <td>70.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>61</td>\n      <td>1</td>\n      <td>30.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>225.0</td>\n      <td>150.0</td>\n      <td>95.0</td>\n      <td>28.58</td>\n      <td>65.0</td>\n      <td>103.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>46</td>\n      <td>1</td>\n      <td>23.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>285.0</td>\n      <td>130.0</td>\n      <td>84.0</td>\n      <td>23.10</td>\n      <td>85.0</td>\n      <td>85.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4235</th>\n      <td>0</td>\n      <td>48</td>\n      <td>1</td>\n      <td>20.0</td>\n      <td>0.169544</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>248.0</td>\n      <td>131.0</td>\n      <td>72.0</td>\n      <td>22.00</td>\n      <td>84.0</td>\n      <td>86.000000</td>\n    </tr>\n    <tr>\n      <th>4236</th>\n      <td>0</td>\n      <td>44</td>\n      <td>1</td>\n      <td>15.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>210.0</td>\n      <td>126.5</td>\n      <td>87.0</td>\n      <td>19.16</td>\n      <td>86.0</td>\n      <td>23.954335</td>\n    </tr>\n    <tr>\n      <th>4237</th>\n      <td>0</td>\n      <td>52</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>269.0</td>\n      <td>133.5</td>\n      <td>83.0</td>\n      <td>21.47</td>\n      <td>80.0</td>\n      <td>107.000000</td>\n    </tr>\n    <tr>\n      <th>4238</th>\n      <td>1</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>185.0</td>\n      <td>141.0</td>\n      <td>98.0</td>\n      <td>25.60</td>\n      <td>67.0</td>\n      <td>72.000000</td>\n    </tr>\n    <tr>\n      <th>4239</th>\n      <td>0</td>\n      <td>39</td>\n      <td>1</td>\n      <td>30.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>196.0</td>\n      <td>133.0</td>\n      <td>86.0</td>\n      <td>20.91</td>\n      <td>85.0</td>\n      <td>80.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>4240 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler, TomekLinks, ClusterCentroids, NearMiss, EditedNearestNeighbours\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n\nrus = RandomUnderSampler()\nX_RUS, y_RUS = rus.fit_resample(X_train, y_train)\n\nrf_model_rus = RandomForestClassifier(random_state=42)\nrf_model_rus.fit(X_RUS, y_RUS)\ny_pred_rus = rf_model_rus.predict(X_test)\nprint(\"Random Undersampling Accuracy:\", accuracy_score(y_test, y_pred_rus))\nprint(classification_report(y_test, y_pred_rus))\n\n\ntl = TomekLinks()\nX_TL, y_TL = tl.fit_resample(X_train, y_train)\n\nrf_model_tl = RandomForestClassifier(random_state=42)\nrf_model_tl.fit(X_TL, y_TL)\ny_pred_tl = rf_model_tl.predict(X_test)\nprint(\"\\nTomek Links Accuracy:\", accuracy_score(y_test, y_pred_tl))\nprint(classification_report(y_test, y_pred_tl))\n\n\ncc = ClusterCentroids()\nX_CC, y_CC = cc.fit_resample(X_train, y_train)\n\nrf_model_cc = RandomForestClassifier(random_state=42)\nrf_model_cc.fit(X_CC, y_CC)\ny_pred_cc = rf_model_cc.predict(X_test)\nprint(\"\\nCluster Centroids Accuracy:\", accuracy_score(y_test, y_pred_cc))\nprint(classification_report(y_test, y_pred_cc))\n\n\nnm = NearMiss()\nX_NM, y_NM = nm.fit_resample(X_train, y_train)\n\nrf_model_nm = RandomForestClassifier(random_state=42)\nrf_model_nm.fit(X_NM, y_NM)\ny_pred_nm = rf_model_nm.predict(X_test)\nprint(\"\\nNearMiss Accuracy:\", accuracy_score(y_test, y_pred_nm))\nprint(classification_report(y_test, y_pred_nm))\n\n\nenn = EditedNearestNeighbours()\nX_ENN, y_ENN = enn.fit_resample(X_train, y_train)\n\nrf_model_enn = RandomForestClassifier(random_state=42)\nrf_model_enn.fit(X_ENN, y_ENN)\ny_pred_enn = rf_model_enn.predict(X_test)\nprint(\"\\nEdited Nearest Neighbours Accuracy:\", accuracy_score(y_test, y_pred_enn))\nprint(classification_report(y_test, y_pred_enn))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:58.521980Z","iopub.execute_input":"2024-09-20T21:51:58.522911Z","iopub.status.idle":"2024-09-20T21:52:10.868055Z","shell.execute_reply.started":"2024-09-20T21:51:58.522862Z","shell.execute_reply":"2024-09-20T21:52:10.867026Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Random Undersampling Accuracy: 0.6470125786163522\n              precision    recall  f1-score   support\n\n           0       0.90      0.65      0.76      1077\n           1       0.24      0.62      0.35       195\n\n    accuracy                           0.65      1272\n   macro avg       0.57      0.63      0.55      1272\nweighted avg       0.80      0.65      0.70      1272\n\n\nTomek Links Accuracy: 0.8514150943396226\n              precision    recall  f1-score   support\n\n           0       0.86      0.99      0.92      1077\n           1       0.58      0.11      0.19       195\n\n    accuracy                           0.85      1272\n   macro avg       0.72      0.55      0.55      1272\nweighted avg       0.82      0.85      0.81      1272\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nCluster Centroids Accuracy: 0.3411949685534591\n              precision    recall  f1-score   support\n\n           0       0.87      0.26      0.40      1077\n           1       0.16      0.79      0.27       195\n\n    accuracy                           0.34      1272\n   macro avg       0.52      0.53      0.33      1272\nweighted avg       0.77      0.34      0.38      1272\n\n\nNearMiss Accuracy: 0.4111635220125786\n              precision    recall  f1-score   support\n\n           0       0.90      0.34      0.50      1077\n           1       0.18      0.78      0.29       195\n\n    accuracy                           0.41      1272\n   macro avg       0.54      0.56      0.39      1272\nweighted avg       0.79      0.41      0.47      1272\n\n\nEdited Nearest Neighbours Accuracy: 0.8128930817610063\n              precision    recall  f1-score   support\n\n           0       0.87      0.91      0.89      1077\n           1       0.35      0.26      0.30       195\n\n    accuracy                           0.81      1272\n   macro avg       0.61      0.59      0.60      1272\nweighted avg       0.79      0.81      0.80      1272\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Lots of empty value fill up with 0","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.under_sampling import TomekLinks\n\ntarget = data['TenYearCHD']\ncolumns_to_drop = ['TenYearCHD','education']\nfeatures = data.drop(columns_to_drop, axis=1)\nx= features.values\ny= target.values\n\ntomeklinks= TomekLinks()\noversample= SMOTE()\nsteps= [(\"TL\", tomeklinks), (\"os\", oversample)]\npipeline= Pipeline(steps=steps)\n\nx_s, y_s = pipeline.fit_resample(x, y)\n\nx_train, x_test,y_train, y_test = train_test_split(x_s, y_s, test_size=0.2, random_state=42)\n\nmodel= RandomForestClassifier(random_state=42)\nmodel.fit(x_train,y_train)\n\ny_pred = model.predict(x_test)\nprint(\"Classification Report:\\n\",classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:52:22.745329Z","iopub.execute_input":"2024-09-20T21:52:22.745804Z","iopub.status.idle":"2024-09-20T21:52:23.988214Z","shell.execute_reply.started":"2024-09-20T21:52:22.745762Z","shell.execute_reply":"2024-09-20T21:52:23.987166Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.88      0.93      0.90       693\n           1       0.92      0.87      0.89       663\n\n    accuracy                           0.90      1356\n   macro avg       0.90      0.90      0.90      1356\nweighted avg       0.90      0.90      0.90      1356\n\n","output_type":"stream"}]},{"cell_type":"code","source":"exc= ExtraTreesClassifier(criterion='entropy', n_estimators= 100, max_depth= 500, min_samples_split= 2, max_features='log2')\nexc.fit(x_train,y_train)\ny_pred= exc.predict(x_test)\nprint(\"classification report: \\n\", classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:52:32.631830Z","iopub.execute_input":"2024-09-20T21:52:32.632261Z","iopub.status.idle":"2024-09-20T21:52:33.439475Z","shell.execute_reply.started":"2024-09-20T21:52:32.632218Z","shell.execute_reply":"2024-09-20T21:52:33.438295Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"classification report: \n               precision    recall  f1-score   support\n\n           0       0.89      0.94      0.92       693\n           1       0.94      0.88      0.91       663\n\n    accuracy                           0.91      1356\n   macro avg       0.92      0.91      0.91      1356\nweighted avg       0.92      0.91      0.91      1356\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\ndf= pd.DataFrame(data)\nimputer= IterativeImputer(max_iter=10, random_state=42)\nimpute_data= imputer.fit_transform(df)\ndata= pd.DataFrame(impute_data, columns= df.columns)\n\ndata","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:52:35.965551Z","iopub.execute_input":"2024-09-20T21:52:35.966015Z","iopub.status.idle":"2024-09-20T21:52:36.385651Z","shell.execute_reply.started":"2024-09-20T21:52:35.965973Z","shell.execute_reply":"2024-09-20T21:52:36.384167Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"      Sex   age  education  currentSmoker  cigsPerDay    BPMeds  \\\n0     1.0  39.0        4.0            0.0         0.0  0.000000   \n1     0.0  46.0        2.0            0.0         0.0  0.000000   \n2     1.0  48.0        1.0            1.0        20.0  0.000000   \n3     0.0  61.0        3.0            1.0        30.0  0.000000   \n4     0.0  46.0        3.0            1.0        23.0  0.000000   \n...   ...   ...        ...            ...         ...       ...   \n4235  0.0  48.0        2.0            1.0        20.0  0.169544   \n4236  0.0  44.0        1.0            1.0        15.0  0.000000   \n4237  0.0  52.0        2.0            0.0         0.0  0.000000   \n4238  1.0  40.0        3.0            0.0         0.0  0.000000   \n4239  0.0  39.0        3.0            1.0        30.0  0.000000   \n\n      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n0                 0.0           0.0       0.0    195.0  106.0   70.0  26.97   \n1                 0.0           0.0       0.0    250.0  121.0   81.0  28.73   \n2                 0.0           0.0       0.0    245.0  127.5   80.0  25.34   \n3                 0.0           1.0       0.0    225.0  150.0   95.0  28.58   \n4                 0.0           0.0       0.0    285.0  130.0   84.0  23.10   \n...               ...           ...       ...      ...    ...    ...    ...   \n4235              0.0           0.0       0.0    248.0  131.0   72.0  22.00   \n4236              0.0           0.0       0.0    210.0  126.5   87.0  19.16   \n4237              0.0           0.0       0.0    269.0  133.5   83.0  21.47   \n4238              0.0           1.0       0.0    185.0  141.0   98.0  25.60   \n4239              0.0           0.0       0.0    196.0  133.0   86.0  20.91   \n\n      heartRate     glucose  TenYearCHD  \n0          80.0   77.000000         0.0  \n1          95.0   76.000000         0.0  \n2          75.0   70.000000         0.0  \n3          65.0  103.000000         1.0  \n4          85.0   85.000000         0.0  \n...         ...         ...         ...  \n4235       84.0   86.000000         0.0  \n4236       86.0   23.954335         0.0  \n4237       80.0  107.000000         0.0  \n4238       67.0   72.000000         0.0  \n4239       85.0   80.000000         0.0  \n\n[4240 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>age</th>\n      <th>education</th>\n      <th>currentSmoker</th>\n      <th>cigsPerDay</th>\n      <th>BPMeds</th>\n      <th>prevalentStroke</th>\n      <th>prevalentHyp</th>\n      <th>diabetes</th>\n      <th>totChol</th>\n      <th>sysBP</th>\n      <th>diaBP</th>\n      <th>BMI</th>\n      <th>heartRate</th>\n      <th>glucose</th>\n      <th>TenYearCHD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>39.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>195.0</td>\n      <td>106.0</td>\n      <td>70.0</td>\n      <td>26.97</td>\n      <td>80.0</td>\n      <td>77.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>46.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>250.0</td>\n      <td>121.0</td>\n      <td>81.0</td>\n      <td>28.73</td>\n      <td>95.0</td>\n      <td>76.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>48.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>245.0</td>\n      <td>127.5</td>\n      <td>80.0</td>\n      <td>25.34</td>\n      <td>75.0</td>\n      <td>70.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>61.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>30.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>225.0</td>\n      <td>150.0</td>\n      <td>95.0</td>\n      <td>28.58</td>\n      <td>65.0</td>\n      <td>103.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>46.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>23.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>285.0</td>\n      <td>130.0</td>\n      <td>84.0</td>\n      <td>23.10</td>\n      <td>85.0</td>\n      <td>85.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4235</th>\n      <td>0.0</td>\n      <td>48.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>0.169544</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>248.0</td>\n      <td>131.0</td>\n      <td>72.0</td>\n      <td>22.00</td>\n      <td>84.0</td>\n      <td>86.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4236</th>\n      <td>0.0</td>\n      <td>44.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>15.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>210.0</td>\n      <td>126.5</td>\n      <td>87.0</td>\n      <td>19.16</td>\n      <td>86.0</td>\n      <td>23.954335</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4237</th>\n      <td>0.0</td>\n      <td>52.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>269.0</td>\n      <td>133.5</td>\n      <td>83.0</td>\n      <td>21.47</td>\n      <td>80.0</td>\n      <td>107.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4238</th>\n      <td>1.0</td>\n      <td>40.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>185.0</td>\n      <td>141.0</td>\n      <td>98.0</td>\n      <td>25.60</td>\n      <td>67.0</td>\n      <td>72.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4239</th>\n      <td>0.0</td>\n      <td>39.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>30.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>196.0</td>\n      <td>133.0</td>\n      <td>86.0</td>\n      <td>20.91</td>\n      <td>85.0</td>\n      <td>80.000000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4240 rows × 16 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#data.dropna(inplace=True) #0.8401639344262295\n# data.fillna(1, inplace=True) # lr=0.8561320754716981\n# data","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.793346Z","iopub.status.idle":"2024-09-20T21:51:06.793726Z","shell.execute_reply.started":"2024-09-20T21:51:06.793524Z","shell.execute_reply":"2024-09-20T21:51:06.793559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df= data.iloc[:4020]\n# count_0=df['TenYearCHD'].eq(0).sum()\n# count_1=df['TenYearCHD'].eq(1).sum()\n\n# print(\"count 0\",count_0)\n# print(\"count 1\",count_1)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.795158Z","iopub.status.idle":"2024-09-20T21:51:06.795555Z","shell.execute_reply.started":"2024-09-20T21:51:06.795367Z","shell.execute_reply":"2024-09-20T21:51:06.795387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.796577Z","iopub.status.idle":"2024-09-20T21:51:06.796985Z","shell.execute_reply.started":"2024-09-20T21:51:06.796773Z","shell.execute_reply":"2024-09-20T21:51:06.796793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data.astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.798431Z","iopub.status.idle":"2024-09-20T21:51:06.798918Z","shell.execute_reply.started":"2024-09-20T21:51:06.798683Z","shell.execute_reply":"2024-09-20T21:51:06.798705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_rows = len(data.columns) + 2\n# plt.figure(figsize=(9, num_rows * 3))\n# for i, col in enumerate(data.columns):\n#     plt.subplot(num_rows, 3, i + 1)\n#     sns.histplot(data=data, x=col , multiple='stack')\n#     plt.xlabel(col)\n# plt.tight_layout()\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.800166Z","iopub.status.idle":"2024-09-20T21:51:06.800552Z","shell.execute_reply.started":"2024-09-20T21:51:06.800362Z","shell.execute_reply":"2024-09-20T21:51:06.800381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.datasets import make_classification\n\nx = features.values\ny = target.values\n\nxx_train, xx_test, yy_train, yy_test = train_test_split(x, y, test_size=0.2, random_state=42)\n\n\nsmote = SMOTE(random_state=42)\nxx_train, yy_train = smote.fit_resample(xx_train, yy_train)\n\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(xx_train, yy_train)\n\nyy_pred = model.predict(xx_test)\n\nprint(\"Classification Report:\\n\", classification_report(yy_test, yy_pred))\n\n# Necessary imports\n# from imblearn.over_sampling import SMOTE\n# from sklearn.model_selection import train_test_split\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.metrics import classification_report\n\n\n# # Convert features and target to numpy arrays (if they are not already)\n# X = features.values\n# y = target.values\n\n# # Split the dataset\n# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# # Apply SMOTE to the training data\n# smote = SMOTE(random_state=42)\n# x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)\n\n# # Train a RandomForestClassifier\n# model = RandomForestClassifier(random_state=42)\n# model.fit(x_train_resampled, y_train_resampled)\n\n# # Make predictions\n# y_pred = model.predict(x_test)\n\n# # Print classification report\n# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:52:40.830196Z","iopub.execute_input":"2024-09-20T21:52:40.830617Z","iopub.status.idle":"2024-09-20T21:52:42.090452Z","shell.execute_reply.started":"2024-09-20T21:52:40.830578Z","shell.execute_reply":"2024-09-20T21:52:42.089341Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.87      0.94      0.90       725\n           1       0.30      0.15      0.20       123\n\n    accuracy                           0.83       848\n   macro avg       0.58      0.55      0.55       848\nweighted avg       0.79      0.83      0.80       848\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef, cohen_kappa_score, confusion_matrix\n\ndef evaluate_model(model, xx_train, yy_train, xx_test, yy_test):\n    # Predictions\n    y_pred_train = model.predict(xx_train)\n    y_pred_test = model.predict(xx_test)\n    \n    accuracy_train = accuracy_score(yy_train, y_pred_train)\n    accuracy_test = accuracy_score(yy_test, y_pred_test)\n    precision_test = precision_score(yy_test, y_pred_test)\n    recall_test = recall_score(yy_test, y_pred_test)\n    f1_test = f1_score(yy_test, y_pred_test)\n    auc = roc_auc_score(yy_test, model.predict_proba(xx_test)[:, 1])\n    mcc_test = matthews_corrcoef(yy_test, y_pred_test)\n    kappa_test = cohen_kappa_score(yy_test, y_pred_test)\n\n    tn, fp, fn, tp = confusion_matrix(yy_test, y_pred_test).ravel()\n    specificity_test = tn / (tn + fp)\n    sensitivity_test = recall_test  \n    \n    print(f\"Train Accuracy: {accuracy_train*100:.2f}%\")\n    print(f\"Test Accuracy: {accuracy_test*100:.2f}%\")\n    print(f\"Precision: {precision_test*100:.2f}%\")\n    print(f\"Recall/Sensitivity: {sensitivity_test*100:.2f}%\")\n    print(f\"Specificity: {specificity_test*100:.2f}%\")\n    print(f\"F1-Score: {f1_test*100:.2f}%\")\n    print(f\"AUC-ROC: {auc*100:.2f}%\")\n    print(f\"MCC: {mcc_test*100:.2f}%\")\n    print(f\"Kappa: {kappa_test*100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:52:50.136012Z","iopub.execute_input":"2024-09-20T21:52:50.136444Z","iopub.status.idle":"2024-09-20T21:52:50.148942Z","shell.execute_reply.started":"2024-09-20T21:52:50.136401Z","shell.execute_reply":"2024-09-20T21:52:50.147762Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n#lr = LogisticRegression(solver='newton-cg',multi_class='multinomial') #0.8561320754716981\n#lr =LogisticRegression(solver='saga', multi_class='multinomial') #0.8561320754716981\nlr = LogisticRegression(solver='liblinear',multi_class='ovr', C=0.1)\nlr.fit(xx_train, yy_train)\nevaluate_model(lr, xx_train, yy_train, xx_test, yy_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:52:53.822259Z","iopub.execute_input":"2024-09-20T21:52:53.822726Z","iopub.status.idle":"2024-09-20T21:52:53.935718Z","shell.execute_reply.started":"2024-09-20T21:52:53.822685Z","shell.execute_reply":"2024-09-20T21:52:53.934320Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Train Accuracy: 67.52%\nTest Accuracy: 63.92%\nPrecision: 22.85%\nRecall/Sensitivity: 62.60%\nSpecificity: 64.14%\nF1-Score: 33.48%\nAUC-ROC: 69.23%\nMCC: 19.24%\nKappa: 15.53%\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import accuracy_score\n\nsgd_clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=5000, random_state=500))\n#sgd_clf.fit(x_train_resampled, y_train_resampled)  #fit(x_train, y_train)\nsgd_clf.fit(xx_train, yy_train)\n\ny_pred = sgd_clf.predict(xx_test)\naccuracy = accuracy_score(yy_test, yy_pred)\nprint(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:52:59.149600Z","iopub.execute_input":"2024-09-20T21:52:59.150088Z","iopub.status.idle":"2024-09-20T21:52:59.208975Z","shell.execute_reply.started":"2024-09-20T21:52:59.150046Z","shell.execute_reply":"2024-09-20T21:52:59.207468Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Test Accuracy: 82.55%\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n#model = DecisionTreeClassifier(random_state=42).fit(x_train_resampled, y_train_resampled) \nmodel = DecisionTreeClassifier(random_state=42).fit(xx_train, yy_train)\n\ntrain_preds = model.predict(xx_train)\nprint(train_preds)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:54:12.901088Z","iopub.execute_input":"2024-09-20T21:54:12.902137Z","iopub.status.idle":"2024-09-20T21:54:12.955421Z","shell.execute_reply.started":"2024-09-20T21:54:12.902086Z","shell.execute_reply":"2024-09-20T21:54:12.954247Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"[0 0 0 ... 1 1 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_preds = model.predict(xx_train)\ntrain_accuracy = accuracy_score(yy_train, train_preds)\nprint(\"Training Accuracy: {:.2f}%\".format(train_accuracy * 100))\ntest_preds = model.predict(xx_test)\ntest_accuracy = accuracy_score(yy_test, test_preds)\nprint(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:54:15.117160Z","iopub.execute_input":"2024-09-20T21:54:15.117639Z","iopub.status.idle":"2024-09-20T21:54:15.128291Z","shell.execute_reply.started":"2024-09-20T21:54:15.117586Z","shell.execute_reply":"2024-09-20T21:54:15.127135Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Training Accuracy: 100.00%\nTest Accuracy: 74.53%\n","output_type":"stream"}]},{"cell_type":"code","source":"model=DecisionTreeClassifier(max_depth=5, random_state=42)\n#model.fit(x_train_resampled, y_train_resampled)\nmodel.fit(xx_train, yy_train)\n\nevaluate_model(model, xx_train, yy_train, xx_test, yy_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.816140Z","iopub.status.idle":"2024-09-20T21:51:06.816728Z","shell.execute_reply.started":"2024-09-20T21:51:06.816411Z","shell.execute_reply":"2024-09-20T21:51:06.816437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n#model=RandomForestClassifier(n_jobs=-1,random_state=42,max_features=2,min_samples_split=80, min_samples_leaf=50,bootstrap=False)\nmodel=RandomForestClassifier(class_weight='balanced')\nmodel.fit(xx_train,yy_train)\nevaluate_model(model, xx_train, yy_train, xx_test, yy_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.818183Z","iopub.status.idle":"2024-09-20T21:51:06.818653Z","shell.execute_reply.started":"2024-09-20T21:51:06.818395Z","shell.execute_reply":"2024-09-20T21:51:06.818415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=RandomForestClassifier(n_jobs=-1,random_state=42,n_estimators=10,max_depth=7,max_leaf_nodes=4,\n                             max_features=32).fit(xx_train, yy_train)\nevaluate_model(model, xx_train, yy_train, xx_test, yy_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.819900Z","iopub.status.idle":"2024-09-20T21:51:06.820330Z","shell.execute_reply.started":"2024-09-20T21:51:06.820111Z","shell.execute_reply":"2024-09-20T21:51:06.820131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngb=GradientBoostingClassifier(learning_rate=.05).fit(xx_train, yy_train)\nevaluate_model(model, xx_train, yy_train, xx_test, yy_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.821808Z","iopub.status.idle":"2024-09-20T21:51:06.822215Z","shell.execute_reply.started":"2024-09-20T21:51:06.822016Z","shell.execute_reply":"2024-09-20T21:51:06.822037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nxgb_classifier = xgb.XGBClassifier(random_state=42,eval_metric='mlogloss')\nxgb_classifier.fit(xx_train, yy_train)\n\ny_pred = xgb_classifier.predict(xx_test)\naccuracy_xgb = accuracy_score(yy_test, y_pred)\nprint(\"XGBoost Accuracy: {:.2f}%\".format(accuracy_xgb * 100))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.823246Z","iopub.status.idle":"2024-09-20T21:51:06.823653Z","shell.execute_reply.started":"2024-09-20T21:51:06.823464Z","shell.execute_reply":"2024-09-20T21:51:06.823484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nmodel =KNeighborsClassifier(n_neighbors=20) \nmodel.fit(xx_train, yy_train)\nevaluate_model(model, xx_train, yy_train, xx_test, yy_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.824761Z","iopub.status.idle":"2024-09-20T21:51:06.825202Z","shell.execute_reply.started":"2024-09-20T21:51:06.824954Z","shell.execute_reply":"2024-09-20T21:51:06.824973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nmodel=AdaBoostClassifier(n_estimators=10, random_state=42) \nmodel.fit(xx_train, yy_train)\nevaluate_model(model, xx_train, yy_train, xx_test, yy_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.826859Z","iopub.status.idle":"2024-09-20T21:51:06.827309Z","shell.execute_reply.started":"2024-09-20T21:51:06.827064Z","shell.execute_reply":"2024-09-20T21:51:06.827085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nexc= ExtraTreesClassifier(criterion='entropy', n_estimators= 100, max_depth= 500, min_samples_split= 2, max_features='log2')\nexc.fit(xx_train,yy_train)\ny_pred= exc.predict(xx_test)\nprint(\"classification report: \\n\", classification_report(yy_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.828448Z","iopub.status.idle":"2024-09-20T21:51:06.828848Z","shell.execute_reply.started":"2024-09-20T21:51:06.828632Z","shell.execute_reply":"2024-09-20T21:51:06.828652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(model, xx_train, yy_train, cv=kf, scoring='accuracy')\nprint(f\"{scores}\")\nprint(f\"Mean Accuracy: {scores.mean():.2f}\")\nprint(f\"Standard Deviation: {scores.std():.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.830004Z","iopub.status.idle":"2024-09-20T21:51:06.830505Z","shell.execute_reply.started":"2024-09-20T21:51:06.830255Z","shell.execute_reply":"2024-09-20T21:51:06.830305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=1)\ncross_val_score(LogisticRegression(solver='liblinear',multi_class='ovr'),x_train, y_train,cv=3)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.831687Z","iopub.status.idle":"2024-09-20T21:51:06.832129Z","shell.execute_reply.started":"2024-09-20T21:51:06.831876Z","shell.execute_reply":"2024-09-20T21:51:06.831895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\nscaled = scaler.fit_transform(features)\nprint(scaled.shape)\nscaled","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.833432Z","iopub.status.idle":"2024-09-20T21:51:06.833822Z","shell.execute_reply.started":"2024-09-20T21:51:06.833631Z","shell.execute_reply":"2024-09-20T21:51:06.833650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Gen = Genarative Adversial Network\ndeep-learning er oversampling","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.836295Z","iopub.status.idle":"2024-09-20T21:51:06.836699Z","shell.execute_reply.started":"2024-09-20T21:51:06.836511Z","shell.execute_reply":"2024-09-20T21:51:06.836530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Generator takes random noise as input and generates data:","metadata":{}},{"cell_type":"code","source":"def build_generator(noise_dim):\n    model = tf.keras.Sequential()\n    \n#     model.add(layers.Dense(16, input_dim= noise_dim))\n#     model.add(layers.LeakyReLU(alpha=0.2))\n#     model.add(layers.BatchNormalization(momentum=0.8))\n    model.add(layers.Dense(32, input_dim= noise_dim),)\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.BatchNormalization(momentum=0.8))\n    model.add(layers.Dense(64))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.BatchNormalization(momentum=0.8))\n    \n    #model.add(layers.Dense(128, input_dim=noise_dim))\n    model.add(layers.Dense(128))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.BatchNormalization(momentum=0.8))\n    model.add(layers.Dense(256))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.BatchNormalization(momentum=0.8))\n    model.add(layers.Dense(512))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.BatchNormalization(momentum=0.8))\n    model.add(layers.Dense(1024))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.BatchNormalization(momentum=0.8))\n    model.add(layers.Dense(np.prod(features.shape[1:]), activation='tanh'))\n    model.add(layers.Reshape(features.shape[1:]))\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.838057Z","iopub.status.idle":"2024-09-20T21:51:06.838468Z","shell.execute_reply.started":"2024-09-20T21:51:06.838237Z","shell.execute_reply":"2024-09-20T21:51:06.838256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Discriminator distinguishes between real and fake data:","metadata":{}},{"cell_type":"code","source":"def build_discriminator(data_shape):\n    model= tf.keras.Sequential()\n    model.add(layers.Flatten(input_shape= data_shape))\n    model.add(layers.Dense(512))\n    model.add(layers.LeakyReLU(alpha= 0.2))\n    model.add(layers.Dense(256))\n    model.add(layers.LeakyReLU(alpha= 0.2))\n    model.add(layers.Dense(128))\n    model.add(layers.LeakyReLU(alpha= 0.2))\n    \n    model.add(layers.Dense(64))\n    model.add(layers.LeakyReLU(alpha= 0.2))\n    model.add(layers.Dense(32))\n    model.add(layers.LeakyReLU(alpha= 0.2))\n    \n    model.add(layers.Dense(1, activation= 'sigmoid'))\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.847416Z","iopub.status.idle":"2024-09-20T21:51:06.847810Z","shell.execute_reply.started":"2024-09-20T21:51:06.847616Z","shell.execute_reply":"2024-09-20T21:51:06.847635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise_dim= 100\ngenerator= build_generator(noise_dim)\ndiscriminator= build_discriminator(features.shape[1:])\ndiscriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# GAN model\ndiscriminator.trainable = False\ngan_input = layers.Input(shape=(noise_dim,))\ngenerated_data = generator(gan_input)\ngan_output = discriminator(generated_data)\n\ngan = tf.keras.Model(gan_input, gan_output)\ngan.compile(loss='binary_crossentropy', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.849184Z","iopub.status.idle":"2024-09-20T21:51:06.849644Z","shell.execute_reply.started":"2024-09-20T21:51:06.849425Z","shell.execute_reply":"2024-09-20T21:51:06.849447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The training process involves training the Discriminator and the Generator\n\nSymmetry around 0 allows the generator to learn from both positive and negative values.\nA standard deviation of 1 provides a good range for the noise, giving enough variation for the generator to create diverse samples.\n\nnp.ones((batch_size, 1)): এখানে আসল ডেটার জন্য লেবেল বা লক্ষ্য মান 1 হিসাবে দেওয়া হচ্ছে। অর্থাৎ, ডিসক্রিমিনেটরকে শেখানো হচ্ছে যে এই ডেটাগুলি আসল।","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# import tensorflow as tf\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Dropout\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras import backend as K\n\n# def build_discriminator(input_shape):\n#     model = Sequential()\n#     model.add(Dense(512, input_dim=input_shape))\n#     model.add(LeakyReLU(alpha=0.2))\n#     model.add(Dropout(0.4))\n#     model.add(Dense(256))\n#     model.add(LeakyReLU(alpha=0.2))\n#     model.add(Dropout(0.4))\n#     model.add(Dense(1, activation='sigmoid'))\n#     return model\n\n# def build_generator(noise_dim):\n#     model = Sequential()\n#     model.add(Dense(256, input_dim=noise_dim))\n#     model.add(LeakyReLU(alpha=0.2))\n#     model.add(BatchNormalization(momentum=0.8))\n#     model.add(Dense(512))\n#     model.add(LeakyReLU(alpha=0.2))\n#     model.add(BatchNormalization(momentum=0.8))\n#     model.add(Dense(1024))\n#     model.add(LeakyReLU(alpha=0.2))\n#     model.add(BatchNormalization(momentum=0.8))\n#     model.add(Dense(features.shape[1], activation='tanh')) \n#     return model\n\n# def build_gan(generator, discriminator):\n#     model = Sequential()\n#     model.add(generator)\n#     discriminator.trainable = False\n#     model.add(discriminator)\n#     return model\n\n# def train_gan(gan, generator, discriminator, features, target, noise_dim, epochs=100, batch_size=64, label_smoothing=0.9, d_steps=2):\n#     discriminator_optimizer = Adam(learning_rate=0.0004, beta_1=0.5)\n#     generator_optimizer = Adam(learning_rate=0.0001, beta_1=0.5)\n    \n#     discriminator.compile(loss='binary_crossentropy', optimizer=discriminator_optimizer, metrics=['accuracy'])\n#     gan.compile(loss='binary_crossentropy', optimizer=generator_optimizer)\n\n#     for epoch in range(epochs):\n#         for _ in range(d_steps):\n#             idx = np.random.randint(0, features.shape[0], batch_size)\n#             real_data = features.iloc[idx].values\n#             real_labels = target.iloc[idx].values.reshape(-1, 1)\n#             real_labels = real_labels * label_smoothing\n\n#             noise = np.random.normal(0, 1, (batch_size, noise_dim))\n#             generated_data = generator.predict(noise)\n#             fake_labels = np.random.uniform(0.0, 0.1, (batch_size, 1))\n\n#             d_loss_real = discriminator.train_on_batch(real_data, real_labels)\n#             d_loss_fake = discriminator.train_on_batch(generated_data, fake_labels)\n\n#             d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n#         noise = np.random.normal(0, 1, (batch_size, noise_dim))\n#         valid_y = np.ones((batch_size, 1))\n#         g_loss = gan.train_on_batch(noise, valid_y)\n\n#         if epoch % 100 == 0:\n#             print(f\"Epoch {epoch}/{epochs} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]:.2f}%] [G loss: {g_loss}]\")\n\n# # Example usage\n# noise_dim = 100\n# epochs = 100\n# batch_size = 64\n\n# discriminator = build_discriminator(features.shape[1])\n# generator = build_generator(noise_dim)\n# gan = build_gan(generator, discriminator)\n\n# train_gan(gan, generator, discriminator, features, target, noise_dim, epochs=epochs, batch_size=batch_size, label_smoothing=0.8, d_steps=2)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.851365Z","iopub.status.idle":"2024-09-20T21:51:06.851723Z","shell.execute_reply.started":"2024-09-20T21:51:06.851537Z","shell.execute_reply":"2024-09-20T21:51:06.851554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def train_gan(gan, generator, discriminator, data, noise_dim, epochs=100, batch_size=64):\n#     for epoch in range(epochs):\n#         # Train the discriminator\n#         idx = np.random.randint(0, data.shape[0], batch_size)\n#         real_data = data.iloc[idx]  # Use .iloc for row indexing\n        \n#         noise = np.random.normal(0, 1, (batch_size, noise_dim))\n#         generated_data = generator.predict(noise)\n        \n#         d_loss_real = discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))\n#         d_loss_fake = discriminator.train_on_batch(generated_data, np.zeros((batch_size, 1)))\n        \n#         d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n        \n#         # Train the generator\n#         noise = np.random.normal(0, 1, (batch_size, noise_dim))\n#         valid_y = np.array([1] * batch_size)\n#         g_loss = gan.train_on_batch(noise, valid_y)\n\n#         if epoch % 100 == 0:\n#             print(f\"Epoch {epoch}/{epochs} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]:.2f}] [G loss: {g_loss}]\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.853179Z","iopub.status.idle":"2024-09-20T21:51:06.853627Z","shell.execute_reply.started":"2024-09-20T21:51:06.853436Z","shell.execute_reply":"2024-09-20T21:51:06.853459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def train_gan(gan, generator, discriminator, features, noise_dim, epochs=100, batch_size=64):\n#     for epoch in range(epochs):\n#         # Train the discriminator\n#         idx = np.random.randint(0, features.shape[0], batch_size)\n#         real_data = features.iloc[idx]  # Use .iloc for integer-based indexing\n        \n#         noise = np.random.normal(0, 1, (batch_size, noise_dim))\n#         generated_data = generator.predict(noise)\n        \n#         d_loss_real = discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))\n#         d_loss_fake = discriminator.train_on_batch(generated_data, np.zeros((batch_size, 1)))\n        \n#         d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n        \n#         # Train the generator\n#         noise = np.random.normal(0, 1, (batch_size, noise_dim))\n#         valid_y = np.array([1] * batch_size)\n#         g_loss = gan.train_on_batch(noise, valid_y)\n\n#         if epoch % 100 == 0:\n#             print(f\"Epoch {epoch}/{epochs} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]:.2f}] [G loss: {g_loss}]\")\n\n# train_gan(gan, generator, discriminator, features, noise_dim, epochs=100, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.854996Z","iopub.status.idle":"2024-09-20T21:51:06.855444Z","shell.execute_reply.started":"2024-09-20T21:51:06.855208Z","shell.execute_reply":"2024-09-20T21:51:06.855229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_gan(gan, generator, discriminator, features, target, noise_dim, epochs=100, batch_size=64):\n    for epoch in range(epochs):\n        # Train & discriminator on real data\n        idx= np.random.randint(0, features.shape[0], batch_size)\n        real_data= features.iloc[idx]  \n        real_labels= target.iloc[idx].values.reshape(-1, 1) \n\n        # Generate data\n        noise= np.random.normal(0, 1, (batch_size, noise_dim))\n        generated_data= generator.predict(noise)\n\n        d_loss_real= discriminator.train_on_batch(real_data, real_labels)\n        d_loss_fake= discriminator.train_on_batch(generated_data, np.zeros((batch_size, 1)))\n        \n        d_loss = 0.5* np.add(d_loss_real, d_loss_fake)\n\n        noise = np.random.normal(0, 1, (batch_size, noise_dim))\n        valid_y = np.ones((batch_size, 1))  # Generator aims to create \"real\" data, so label it as 1\n        g_loss = gan.train_on_batch(noise, valid_y)\n\n        if epoch % 100 == 0:\n            print(f\"Epoch {epoch}/{epochs} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]:.2f}%] [G loss: {g_loss}]\")\ntrain_gan(gan, generator, discriminator, features, target,noise_dim, epochs=100, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.857013Z","iopub.status.idle":"2024-09-20T21:51:06.857424Z","shell.execute_reply.started":"2024-09-20T21:51:06.857196Z","shell.execute_reply":"2024-09-20T21:51:06.857215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_synthetic_data(generator, noise_dim, num_zeros, num_ones):\n    noise_for_zeros = np.random.normal(0, 1, (num_zeros, noise_dim))\n    generated_zeros = generator.predict(noise_for_zeros)\n\n    noise_for_ones = np.random.normal(0, 1, (num_ones, noise_dim))\n    generated_ones = generator.predict(noise_for_ones)\n\n    generated_data = np.concatenate([generated_zeros, generated_ones], axis=0)\n    \n    generated_labels = np.concatenate([np.zeros((num_zeros, 1)), np.ones((num_ones, 1))], axis=0)\n    return generated_data, generated_labels\n\nnum_generated_zeros = 10\nnum_generated_ones = 4000  \n\ngenerated_data, generated_labels = generate_synthetic_data(generator, noise_dim, num_generated_zeros, num_generated_ones)\ncombined_data = np.concatenate([features, generated_data], axis=0)\ncombined_targets = np.concatenate([target.values.reshape(-1, 1), generated_labels], axis=0)\n\nprint(f\"Generated {num_generated_zeros} samples with label 0 and {num_generated_ones} samples with label 1.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.859037Z","iopub.status.idle":"2024-09-20T21:51:06.859473Z","shell.execute_reply.started":"2024-09-20T21:51:06.859231Z","shell.execute_reply":"2024-09-20T21:51:06.859252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_generated_samples = 10000\n\n# # Generate synthetic data\n# noise = np.random.normal(0, 1, (num_generated_samples, noise_dim))\n# generated_data = generator.predict(noise)\n\n# combined_data = np.concatenate([features, generated_data], axis=0)\n# combined_targets = np.concatenate([target, np.ones(num_generated_samples)], axis=0)  #synthetic data targets are 1","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.860871Z","iopub.status.idle":"2024-09-20T21:51:06.861269Z","shell.execute_reply.started":"2024-09-20T21:51:06.861060Z","shell.execute_reply":"2024-09-20T21:51:06.861080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_zeros = np.sum(combined_targets == 0)\ncount_ones = np.sum(combined_targets == 1)\n\nprint(f\"Count of 0s (No Heart Attack): {count_zeros}\")\nprint(f\"Count of 1s (Heart Attack): {count_ones}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.862530Z","iopub.status.idle":"2024-09-20T21:51:06.862945Z","shell.execute_reply.started":"2024-09-20T21:51:06.862744Z","shell.execute_reply":"2024-09-20T21:51:06.862764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.manifold import TSNE # Apply t-SNE to reduce dimensions to 2D\n# import matplotlib.pyplot as plt\n\n# tsne = TSNE(n_components=2, random_state=42)\n# combined_data_2d = tsne.fit_transform(combined_data)\n\n# plt.figure(figsize=(8, 6))\n# plt.scatter(combined_data_2d[:len(data), 0], combined_data_2d[:len(data), 1], c='blue', label='Real Data')\n# plt.scatter(combined_data_2d[len(data):, 0], combined_data_2d[len(data):, 1], c='red', label='Synthetic Data')\n# plt.legend()\n# plt.title(\"Real and Synthetic Data\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.864004Z","iopub.status.idle":"2024-09-20T21:51:06.864435Z","shell.execute_reply.started":"2024-09-20T21:51:06.864212Z","shell.execute_reply":"2024-09-20T21:51:06.864232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.decomposition import PCA #Apply PCA to reduce dimensions to 2D\n# import matplotlib.pyplot as plt \n# pca = PCA(n_components=2)\n# combined_data_2d = pca.fit_transform(combined_data)\n\n# plt.figure(figsize=(8, 6))\n# plt.scatter(combined_data_2d[:len(data), 0], combined_data_2d[:len(data), 1], c='blue', label='Real Data')\n# plt.scatter(combined_data_2d[len(data):, 0], combined_data_2d[len(data):, 1], c='red', label='Synthetic Data')\n# plt.legend()\n# plt.title(\"PCA Visualization of Real and Synthetic Data\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.866392Z","iopub.status.idle":"2024-09-20T21:51:06.866814Z","shell.execute_reply.started":"2024-09-20T21:51:06.866594Z","shell.execute_reply":"2024-09-20T21:51:06.866614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# if the data length and the combinded data length size are not similer","metadata":{}},{"cell_type":"code","source":"# from sklearn.preprocessing import MinMaxScaler\n# from sklearn.model_selection import train_test_split\n# import numpy as np\n\n# num_generated_samples = 2700\n# noise_dim = 100  \n# features = np.random.rand(5000, 14)  # Replace with actual features\n# target = np.random.randint(0, 2, size=(5000,))  # Replace with actual target\n\n# noise = np.random.normal(0, 1, (num_generated_samples, noise_dim))\n# generated_data = generator.predict(noise)  # Ensure the generator's output shape matches the features shape\n\n# combined_data = np.concatenate([features, generated_data], axis=0)\n# combined_targets = np.concatenate([target, np.ones(num_generated_samples)], axis=0)\n\n# # Ensure that the lengths match\n# if len(combined_data) != len(combined_targets):\n#     min_length = min(len(combined_data), len(combined_targets))\n#     combined_data = combined_data[:min_length]\n#     combined_targets = combined_targets[:min_length]\n\n# scaler = MinMaxScaler(feature_range=(-1, 1))\n# scaled_combined_data = scaler.fit_transform(combined_data)\n\n# x_train, x_test, y_train, y_test = train_test_split(scaled_combined_data, combined_targets, test_size=0.2, random_state=42)\n\n# print('Train shape:', x_train.shape)\n# print('Test shape:', x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.868302Z","iopub.status.idle":"2024-09-20T21:51:06.868659Z","shell.execute_reply.started":"2024-09-20T21:51:06.868481Z","shell.execute_reply":"2024-09-20T21:51:06.868499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(combined_data, combined_targets, test_size=0.2, random_state=42)\n\nprint('Train shape:', x_train.shape)\nprint('Test shape:', x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.870103Z","iopub.status.idle":"2024-09-20T21:51:06.870536Z","shell.execute_reply.started":"2024-09-20T21:51:06.870328Z","shell.execute_reply":"2024-09-20T21:51:06.870349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nexc= ExtraTreesClassifier(criterion='entropy', n_estimators= 100, max_depth= 500, min_samples_split= 2, max_features='log2')\nexc.fit(x_train,y_train.ravel())\ny_pred= exc.predict(x_test)\nprint(\"classification report: \\n\", classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.871782Z","iopub.status.idle":"2024-09-20T21:51:06.872152Z","shell.execute_reply.started":"2024-09-20T21:51:06.871954Z","shell.execute_reply":"2024-09-20T21:51:06.871972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifiers = {\n    \"RandomForest\": RandomForestClassifier(random_state=42),\n    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n    \"ExtraTrees\": ExtraTreesClassifier(random_state=42),\n    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n    \"Bagging\": BaggingClassifier(random_state=42),\n    \"HistGradientBoosting\": HistGradientBoostingClassifier(random_state=42),\n    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n    \"LogisticRegression\": LogisticRegression(random_state=42),\n    \"GaussianNB\": GaussianNB(),\n    \"BernoulliNB\": BernoulliNB(),\n    #\"MultinomialNB\": MultinomialNB(),\n    \"KNeighbors\": KNeighborsClassifier(),\n    #\"RadiusNeighbors\": RadiusNeighborsClassifier(),\n    \"SVC\": SVC(probability=True, random_state=42),\n    \"XGBoost\": XGBClassifier(random_state=42),\n    \"LightGBM\": LGBMClassifier(random_state=42),\n    \"MLPClassifier\": MLPClassifier(random_state=42)\n}\nresults_df = pd.DataFrame(columns=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall', 'Specificity', 'ROC-AUC', 'Confusion Matrix'])\n\n\ndef evaluate_classifiers(classifiers, x_train, x_test, y_train, y_test):\n    global results_df\n    for name, clf in classifiers.items():\n        try:\n            clf.fit(x_train, y_train) \n            y_pred = clf.predict(x_test)  \n\n            cm = confusion_matrix(y_test, y_pred)\n            if len(cm.ravel()) == 4:  \n                tn, fp, fn, tp = cm.ravel()\n                specificity = tn / (tn + fp) \n            else:\n                specificity = None\n\n            acc = accuracy_score(y_test, y_pred)\n            f1 = f1_score(y_test, y_pred, average='weighted')\n            report = classification_report(y_test, y_pred, output_dict=True)\n            precision = report['weighted avg']['precision']\n            recall = report['weighted avg']['recall']\n\n            if hasattr(clf, \"predict_proba\"): \n                y_proba = clf.predict_proba(x_test)[:, 1]\n                roc_auc = roc_auc_score(y_test, y_proba)\n            else:\n                roc_auc = None\n                \n            new_row = pd.DataFrame({\n                'Model': [name],\n                'Accuracy': [acc],\n                'F1 Score': [f1],\n                'Precision': [precision],\n                'Recall': [recall],\n                'Specificity': [specificity],\n                'ROC-AUC': [roc_auc],\n                'Confusion Matrix': [cm]\n            })\n            results_df = pd.concat([results_df, new_row], ignore_index=True)\n\n        except (ValueError, NotFittedError) as e:\n            print(f\"Error with classifier {name}: {e}\")\n            \nevaluate_classifiers(classifiers, x_train, x_test, y_train, y_test)\nprint(results_df)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.873391Z","iopub.status.idle":"2024-09-20T21:51:06.873826Z","shell.execute_reply.started":"2024-09-20T21:51:06.873628Z","shell.execute_reply":"2024-09-20T21:51:06.873648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# x_train, x_test, y_train, y_test = train_test_split(scaled, target, test_size=0.2,random_state=42)\n\n# print('Train shape:', x_train.shape)\n# print('Test shape:', x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.875162Z","iopub.status.idle":"2024-09-20T21:51:06.875567Z","shell.execute_reply.started":"2024-09-20T21:51:06.875372Z","shell.execute_reply":"2024-09-20T21:51:06.875392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\nlgbm = lgb.LGBMClassifier(\n    boosting_type='dart',\n    learning_rate=0.05,\n    n_estimators=40,\n    num_leaves=31,\n    random_state=42\n)\nlgbm.fit(x_train, y_train)\n\ny_pred = lgbm.predict(x_test)\ny_prob = lgbm.predict_proba(x_test)[:, 1]\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nroc_auc = roc_auc_score(y_test, y_prob)\n\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'F1 Score: {f1:.4f}')\nprint(f'ROC AUC Score: {roc_auc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.876900Z","iopub.status.idle":"2024-09-20T21:51:06.877305Z","shell.execute_reply.started":"2024-09-20T21:51:06.877090Z","shell.execute_reply":"2024-09-20T21:51:06.877110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import lightgbm as lgb\n# import pandas as pd\n# from sklearn.model_selection import train_test_split, GridSearchCV\n# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n\n# lgbm = lgb.LGBMClassifier(random_state=42)\n\n# param_grid = {\n#     'boosting_type': ['gbdt', 'dart', 'rf'],\n#     'num_leaves': [31, 50, 100],\n#     'learning_rate': [0.01, 0.05, 0.1],\n#     'n_estimators': [20, 40, 60, 80, 100]\n# }\n\n# grid_search = GridSearchCV(estimator=lgbm, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n\n# grid_search.fit(x_train, y_train)\n\n# best_params = grid_search.best_params_\n# best_model = grid_search.best_estimator_\n\n# print(f'Best Parameters: {best_params}')\n\n# y_pred = best_model.predict(x_test)\n# y_prob = best_model.predict_proba(x_test)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.879152Z","iopub.status.idle":"2024-09-20T21:51:06.879577Z","shell.execute_reply.started":"2024-09-20T21:51:06.879372Z","shell.execute_reply":"2024-09-20T21:51:06.879394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# functional model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\ntarget = data['TenYearCHD']\ncolumns_to_drop = ['TenYearCHD','education']\nfeatures = data.drop(columns_to_drop, axis=1)\nx = features.values\ny = target.values\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\nscaler = StandardScaler()\nx_train_scaled = scaler.fit_transform(x_train)\nx_test_scaled = scaler.transform(x_test)\n\noptimizer = Adam(learning_rate=0.02)\n\ndef build_model(input_dim):\n    inputs = Input(shape=(input_dim,))\n    x = Dense(128, activation='relu')(inputs)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(64, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    outputs = Dense(1, activation='sigmoid')(x) \n    \n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\ninput_dim = x_train_scaled.shape[1]\nmodel = build_model(input_dim)\n\nearly_stopping = EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)\nhistory = model.fit(x_train_scaled, y_train, \n                    epochs=100, \n                    batch_size=32, \n                    validation_split=0.2, \n                    callbacks=[early_stopping],\n                    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.880933Z","iopub.status.idle":"2024-09-20T21:51:06.881348Z","shell.execute_reply.started":"2024-09-20T21:51:06.881119Z","shell.execute_reply":"2024-09-20T21:51:06.881137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(x_test_scaled, y_test)\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\ny_pred = (model.predict(x_test_scaled) > 0.5).astype(\"int32\") \nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.882612Z","iopub.status.idle":"2024-09-20T21:51:06.883025Z","shell.execute_reply.started":"2024-09-20T21:51:06.882811Z","shell.execute_reply":"2024-09-20T21:51:06.882831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sequential Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\n\ndef build_sequential_model(input_dim, learning_rate=0.001):\n    model = Sequential()\n    model.add(Dense(128, activation='relu', input_dim=input_dim))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(64, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid')) \n    optimizer = Adam(learning_rate=learning_rate)\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\ninput_dim = x_train_scaled.shape[1]\nmodel = build_sequential_model(input_dim)\n\nhistory = model.fit(\n    x_train_scaled, \n    y_train, \n    epochs=100, \n    batch_size=32, \n    validation_split=0.2, \n    callbacks=[early_stopping],\n    verbose=1\n)\ntest_loss, test_accuracy = model.evaluate(x_test_scaled, y_test, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.884300Z","iopub.status.idle":"2024-09-20T21:51:06.884679Z","shell.execute_reply.started":"2024-09-20T21:51:06.884490Z","shell.execute_reply":"2024-09-20T21:51:06.884509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef, cohen_kappa_score, confusion_matrix\n\n# def evaluate_model(model, x_train, y_train, x_test, y_test):\n#     # Predictions\n#     y_pred_train = model.predict(x_train)\n#     y_pred_test = model.predict(x_test)\n    \n#     accuracy_train= accuracy_score(y_train, y_pred_train)\n#     accuracy_test= accuracy_score(y_test, y_pred_test)\n#     precision_test= precision_score(y_test, y_pred_test)\n#     recall_test= recall_score(y_test, y_pred_test)\n#     f1_test= f1_score(y_test, y_pred_test)\n#     auc= roc_auc_score(y_test, model.predict_proba(x_test)[:, 1])\n#     mcc_test= matthews_corrcoef(y_test, y_pred_test)\n#     kappa_test= cohen_kappa_score(y_test, y_pred_test)\n\n#     tn, fp, fn, tp= confusion_matrix(y_test, y_pred_test).ravel()\n#     specificity_test= tn / (tn + fp)\n#     sensitivity_test= recall_test  \n    \n#     print(f\"Train Accuracy: {accuracy_train*100:.2f}%\")\n#     print(f\"Test Accuracy: {accuracy_test*100:.2f}%\")\n#     print(f\"Precision: {precision_test*100:.2f}%\")\n#     print(f\"Recall/Sensitivity: {sensitivity_test*100:.2f}%\")\n#     print(f\"Specificity: {specificity_test*100:.2f}%\")\n#     print(f\"F1-Score: {f1_test*100:.2f}%\")\n#     print(f\"AUC-ROC: {auc*100:.2f}%\")\n#     print(f\"MCC: {mcc_test*100:.2f}%\")\n#     print(f\"Kappa: {kappa_test*100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.886335Z","iopub.status.idle":"2024-09-20T21:51:06.886833Z","shell.execute_reply.started":"2024-09-20T21:51:06.886566Z","shell.execute_reply":"2024-09-20T21:51:06.886591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n#lr = LogisticRegression(solver='newton-cg',multi_class='multinomial') #0.8561320754716981\n#lr =LogisticRegression(solver='saga', multi_class='multinomial') #0.8561320754716981\nlr = LogisticRegression(solver='liblinear',multi_class='ovr', C=0.1)\n#lr.fit(x_train_resampled, y_train_resampled) #fit(x_train, y_train)\nlr.fit(x_train, y_train)\nevaluate_model(lr, x_train, y_train, x_test, y_test)\n\n# import shap\n# explainer = shap.Explainer(lr, x_train)\n# shap_values = explainer.shap_values(x_test[:100])\n# plt.figure(figsize=(16, 12))\n# shap.summary_plot(shap_values, features=x_test[:100], feature_names=features.columns)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.887993Z","iopub.status.idle":"2024-09-20T21:51:06.888541Z","shell.execute_reply.started":"2024-09-20T21:51:06.888240Z","shell.execute_reply":"2024-09-20T21:51:06.888288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from imblearn.over_sampling import SMOTE\n# from sklearn.linear_model import LogisticRegression\n\n# smote = SMOTE(random_state=42)\n# x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)\n\n# lr = LogisticRegression(solver='liblinear', multi_class='ovr')\n# lr.fit(x_train_resampled, y_train_resampled)\n\n# accuracy = lr.score(x_test, y_test) * 100\n# print(f\"Accuracy: {accuracy:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.889810Z","iopub.status.idle":"2024-09-20T21:51:06.890203Z","shell.execute_reply.started":"2024-09-20T21:51:06.890004Z","shell.execute_reply":"2024-09-20T21:51:06.890024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from imblearn.under_sampling import RandomUnderSampler\n# #rus = RandomUnderSampler(sampling_strategy=0.4, random_state=42) #drop 0% data\n# rus = RandomUnderSampler(random_state=42)\n# x_train_resampled, y_train_resampled = rus.fit_resample(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.891661Z","iopub.status.idle":"2024-09-20T21:51:06.892046Z","shell.execute_reply.started":"2024-09-20T21:51:06.891856Z","shell.execute_reply":"2024-09-20T21:51:06.891875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_train_resampled_series = pd.Series(y_train_resampled, name='TenYearCHD')\n\n# class_counts = x_train_resampled_series.value_counts()\n\n# count_0 = class_counts.get(0, 0) \n# count_1 = class_counts.get(1, 0)  \n# print(f\"{count_0}\")\n# print(f\"{count_1}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.893320Z","iopub.status.idle":"2024-09-20T21:51:06.893720Z","shell.execute_reply.started":"2024-09-20T21:51:06.893509Z","shell.execute_reply":"2024-09-20T21:51:06.893529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SGDClassifier","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import accuracy_score\n\nsgd_clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=5000, random_state=500))\n#sgd_clf.fit(x_train_resampled, y_train_resampled)  #fit(x_train, y_train)\nsgd_clf.fit(x_train, y_train)\n\ny_pred = sgd_clf.predict(x_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.895346Z","iopub.status.idle":"2024-09-20T21:51:06.895732Z","shell.execute_reply.started":"2024-09-20T21:51:06.895533Z","shell.execute_reply":"2024-09-20T21:51:06.895552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DecisionTreeClassifier","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n#model = DecisionTreeClassifier(random_state=42).fit(x_train_resampled, y_train_resampled) \nmodel = DecisionTreeClassifier(random_state=42).fit(x_train, y_train)\n\ntrain_preds = model.predict(x_train)\nprint(train_preds)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.896992Z","iopub.status.idle":"2024-09-20T21:51:06.897431Z","shell.execute_reply.started":"2024-09-20T21:51:06.897184Z","shell.execute_reply":"2024-09-20T21:51:06.897203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preds = model.predict(x_train)\ntrain_accuracy = accuracy_score(y_train, train_preds)\nprint(\"Training Accuracy: {:.2f}%\".format(train_accuracy * 100))\ntest_preds = model.predict(x_test)\ntest_accuracy = accuracy_score(y_test, test_preds)\nprint(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.898855Z","iopub.status.idle":"2024-09-20T21:51:06.899333Z","shell.execute_reply.started":"2024-09-20T21:51:06.899046Z","shell.execute_reply":"2024-09-20T21:51:06.899072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=DecisionTreeClassifier(max_depth=7, random_state=42)\n#model.fit(x_train_resampled, y_train_resampled)\nmodel.fit(x_train, y_train)\n\nevaluate_model(model, x_train, y_train, x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.900474Z","iopub.status.idle":"2024-09-20T21:51:06.900870Z","shell.execute_reply.started":"2024-09-20T21:51:06.900673Z","shell.execute_reply":"2024-09-20T21:51:06.900694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n#model=RandomForestClassifier(n_jobs=-1,random_state=42,max_features=2,min_samples_split=80, min_samples_leaf=50,bootstrap=False)\nmodel=RandomForestClassifier(class_weight='balanced')\nmodel.fit(x_train,y_train)\nmodel.fit(x_train,y_train)\nevaluate_model(model, x_train, y_train, x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.902334Z","iopub.status.idle":"2024-09-20T21:51:06.902709Z","shell.execute_reply.started":"2024-09-20T21:51:06.902517Z","shell.execute_reply":"2024-09-20T21:51:06.902536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=RandomForestClassifier(n_jobs=-1,random_state=42,n_estimators=5,max_depth=7,max_leaf_nodes=4,\n                             max_features=32).fit(x_train, y_train)\nevaluate_model(model, x_train, y_train, x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.904458Z","iopub.status.idle":"2024-09-20T21:51:06.904835Z","shell.execute_reply.started":"2024-09-20T21:51:06.904646Z","shell.execute_reply":"2024-09-20T21:51:06.904665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNeighborsClassifier","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nmodel =KNeighborsClassifier(n_neighbors=20) \nmodel.fit(x_train, y_train)\nevaluate_model(model, x_train, y_train, x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.906127Z","iopub.status.idle":"2024-09-20T21:51:06.906542Z","shell.execute_reply.started":"2024-09-20T21:51:06.906330Z","shell.execute_reply":"2024-09-20T21:51:06.906355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AdaBoostClassifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nmodel=AdaBoostClassifier(n_estimators=10, random_state=42) \nmodel.fit(x_train, y_train)\nevaluate_model(model, x_train, y_train, x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.908366Z","iopub.status.idle":"2024-09-20T21:51:06.908787Z","shell.execute_reply.started":"2024-09-20T21:51:06.908574Z","shell.execute_reply":"2024-09-20T21:51:06.908595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# xgBoosting","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\nxgb_classifier = xgb.XGBClassifier(random_state=42,eval_metric='mlogloss')\nxgb_classifier.fit(x_train, y_train)\n\ny_pred = xgb_classifier.predict(x_test)\naccuracy_xgb = accuracy_score(y_test, y_pred)\nprint(\"XGBoost Test Accuracy: {:.2f}%\".format(accuracy_xgb * 100))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.909941Z","iopub.status.idle":"2024-09-20T21:51:06.910428Z","shell.execute_reply.started":"2024-09-20T21:51:06.910144Z","shell.execute_reply":"2024-09-20T21:51:06.910166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gradient Boosting Classifire","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngb=GradientBoostingClassifier(learning_rate=.02).fit(x_train,y_train)\nevaluate_model(model, x_train, y_train, x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.912478Z","iopub.status.idle":"2024-09-20T21:51:06.912883Z","shell.execute_reply.started":"2024-09-20T21:51:06.912682Z","shell.execute_reply":"2024-09-20T21:51:06.912703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(model, x_train, y_train, cv=kf, scoring='accuracy')\n\nprint(f\"{scores}\")\nprint(f\"Mean Accuracy: {scores.mean():.2f}\")\nprint(f\"Standard Deviation: {scores.std():.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.914237Z","iopub.status.idle":"2024-09-20T21:51:06.914709Z","shell.execute_reply.started":"2024-09-20T21:51:06.914504Z","shell.execute_reply":"2024-09-20T21:51:06.914526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=1)\ncross_val_score(LogisticRegression(solver='liblinear',multi_class='ovr'),x_train, y_train,cv=3)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.916332Z","iopub.status.idle":"2024-09-20T21:51:06.916687Z","shell.execute_reply.started":"2024-09-20T21:51:06.916508Z","shell.execute_reply":"2024-09-20T21:51:06.916526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# fully conected Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.optimizers import Adam\n\ninput_shape= (14,)\ninputs= Input(shape= input_shape)\n\nx= Dense(512, activation='relu')(inputs)\nx= Dense(256, activation= 'relu')(x)\nx= Dense(128, activation= 'relu')(x)\nx= Dense(64, activation= 'relu')(x)\nx= Dense(32, activation= 'relu')(x)\nx= Dense(16, activation= 'relu')(x)\n# x= Dense(4, activation= 'relu')(x)\n\noutput= Dense(1, activation= 'sigmoid')(x)\n\nmodel= Model(inputs= inputs, outputs= output)\n\nmodel.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.917850Z","iopub.status.idle":"2024-09-20T21:51:06.918295Z","shell.execute_reply.started":"2024-09-20T21:51:06.918079Z","shell.execute_reply":"2024-09-20T21:51:06.918101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history= model.fit(\n    x_train,\n    y_train,\n    epochs= 100,\n    verbose= 1,\n    batch_size= 32\n    )","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.919685Z","iopub.status.idle":"2024-09-20T21:51:06.920130Z","shell.execute_reply.started":"2024-09-20T21:51:06.919892Z","shell.execute_reply":"2024-09-20T21:51:06.919914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ndef predict_heart_attack(model, features, scaler=None):\n    feature_names = [\n        'Sex', 'age', 'currentSmoker', 'cigsPerDay', 'BPMeds', 'prevalentStroke',\n        'prevalentHyp', 'diabetes', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose'\n    ]\n    \n    # Convert features dictionary to DataFrame\n    features_df = pd.DataFrame([features], columns=feature_names)\n    if scaler:\n        features_df = scaler.transform(features_df)\n\n    prediction = model.predict(features_df)\n    \n    return prediction[0]\n\nsgd_model = make_pipeline(StandardScaler(), SGDClassifier(max_iter=5000, random_state=500)).fit(x_train, y_train)\ndt_model = DecisionTreeClassifier(max_depth=7, random_state=63).fit(x_train, y_train)\n\ninput_features = {\n    'Sex': 1,               \n    'age': 61,\n    'currentSmoker': 1,     \n    'cigsPerDay': 30,\n    'BPMeds': 0,\n    'prevalentStroke': 0,\n    'prevalentHyp': 1,      \n    'diabetes': 0,\n    'totChol': 255,\n    'sysBP': 150,\n    'diaBP': 95,\n    'BMI': 28.58,\n    'heartRate': 65,\n    'glucose': 103\n}\n\nsgd_result = predict_heart_attack(sgd_model, input_features, scaler=sgd_model.named_steps['standardscaler'])\nprint(f'SGDClassifier Predicted result: {\"Heart Attack\" if sgd_result == 1 else \"No Heart Attack\"}')\n\ndt_result = predict_heart_attack(dt_model, input_features)\nprint(f'DecisionTreeClassifier Predicted result: {\"Heart Attack\" if dt_result == 1 else \"No Heart Attack\"}')","metadata":{"execution":{"iopub.status.busy":"2024-09-20T21:51:06.921525Z","iopub.status.idle":"2024-09-20T21:51:06.921899Z","shell.execute_reply.started":"2024-09-20T21:51:06.921709Z","shell.execute_reply":"2024-09-20T21:51:06.921728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}